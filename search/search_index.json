{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"concepts/","title":"Welcome","text":""},{"location":"concepts/#concepts","title":"Concepts","text":""},{"location":"concepts/#welcome","title":"Welcome!","text":"<p>Welcome to OSSVerse's documentation! Here you will find the concepts you need to understand to work with the decentralized marketplace, the steps to try OSSVerse by yourself, and the extensive documentation about every aspect of our solution.</p>"},{"location":"concepts/#getting-started","title":"Getting Started","text":"<p>Feel free to explore the following pages to know more about OSSVerse.</p> <ul> <li>  See What is OSSVerse to fully understand what OSSVerse is.</li> <li>  See Why OSSVerse to help you decide whether OSSVerse is the right place for you.</li> <li>  See What can OSSVerse do for you to understand more about the capabilities of OSSVerse.</li> <li>  See Our Tech Stack to learn about our design choices for the technology stack.</li> </ul>"},{"location":"concepts/assurance-provider/","title":"Assurance provider","text":""},{"location":"concepts/assurance-provider/#oasp-user-flow","title":"OASP User Flow","text":""},{"location":"concepts/marketplace-operator/","title":"Marketplace operator","text":""},{"location":"concepts/marketplace-operator/#marketplace-operator-flow","title":"Marketplace Operator Flow","text":""},{"location":"concepts/next-steps/","title":"Next Steps","text":"<p>Now that you know the basic concepts about Leverage feel free to give it a try or check out the User Guide section to go deeper into the implementation details. Links down below:</p>"},{"location":"concepts/next-steps/#learn-more","title":"Learn More","text":"<p> See Try Leverage to take the tutorial that will help you deploy a basic AWS Landing Zone via Leverage.</p> <p> See User Guide to take the comprehensive route to learn more about Leverage.</p> <p> See Work with us if you want to join us or know more about the team behind Leverage.</p>"},{"location":"concepts/oss-consumer/","title":"Open Source Assurance Service Demand and Orders","text":"<p>The automotive business facing infrastructure captures consumers\u2019 requests via its UI application, converts them into beckn-compliant schemas and APIs at the server side, and fires them at the network. OSSVerse business application is the initiator of transactions and have the flexibility to communicate with multiple networks and integrate the responses from these networks into a bundled transaction experience.</p>"},{"location":"concepts/oss-consumer/#catalogue-search","title":"Catalogue Search","text":"<p>Discover assurance service providers and their service catalogue via the OSSVerse open network. </p>"},{"location":"concepts/oss-consumer/#place-an-order","title":"Place an order","text":""},{"location":"concepts/oss-consumer/#business-user-flow","title":"Business User Flow","text":""},{"location":"concepts/tech-stack/","title":"Tech Stack","text":"<p>OSSVerse is built around the Beckn Protocol and it uses a stack that includes Beckn-Onix, BeSecure, BeSLab and other tools.</p> <p>We are also adopters and supporters of Open Source and the Cloud Native movement, which should become self-evident as you keep exploring our technology stack.</p>"},{"location":"concepts/tech-stack/#why-did-we-choose-our-tech-stack","title":"Why did we choose our tech stack?","text":"Why Beckn\u2753 <p>Amazon Web Services (AWS) is the world\u2019s most comprehensive and broadly adopted  cloud platform, offering over 200 fully featured services from data centers globally. Millions of customers\u2014including the fastest-growing startups, largest enterprises, and leading government agencies\u2014are using AWS to lower costs, become more agile, and innovate faster.</p> <p>Build, Deploy, and Manage Websites, Apps or Processes On AWS' Secure, Reliable Network. AWS is Secure, Reliable, Scalable Services. HIPAA Compliant. Easily Manage Clusters. Global Infrastructure. Highly Scalable.</p> <p> Read More: What is AWS</p> Why BeSecure\u2753 <p>AWS Well-Architected helps cloud architects to build secure, high-performing, resilient, and efficient infrastructure for their applications and workloads. Based on five pillars \u2014 operational excellence, security, reliability, performance efficiency, and cost optimization \u2014 AWS Well-Architected provides a consistent approach for customers and partners to evaluate architectures, and implement designs that can scale over time.</p> <p> Read More: AWS Well-architected</p> Why Security as Code\u2753 <ul> <li> <p> Confidence: A change breaks the env? Just roll it back. Still not working? Build a whole new env with a few keystrokes. IaC enables this.</p> </li> <li> <p> Repeatability: Allows your infra to be automatically instantiated, making it easy to build multiple identical envs.</p> </li> <li> <p> Troubleshooting: Check source control and see exactly what changed in the env.  As long as you are diligent and don\u2019t make manual envs changes, then IaC can be a game changer.</p> </li> <li> <p> DR: Require the ability to set up an alternate env in a different DC or Region. IaC makes this a much more manageable prospect.</p> </li> <li> <p> Auditability: You will need to be able to audit both changes and access to an env, IaC gives you this right out of the box.</p> </li> <li> <p> Visibility: As an env expands over time, is challenging to tell what has been provisioned. In the #cloud this can be a huge #cost issue. IaC allows tracking your resources.</p> </li> <li> <p> Portability: Some IaC techs are #multicloud. Also, translating #Terraform from one cloud provider to another is considerably more simple than recreating your entire envs in a cloud-specific tool.</p> </li> <li> <p> Security: See history of changes to your SG rules along with commit messages can do wonders for being confident about the security configs of your envs.</p> </li> </ul> <p>Terraform allows to codify your application infrastructure, reduce human error and  increase automation by provisioning infrastructure as code. With TF we can manage infrastructure across clouds and provision infrastructure  across 300+ public clouds and services using a single workflow. Moreover it helps to create reproducible infrastructure and provision consistent testing, staging, and production environments with the same configuration.</p> <p>Terraform has everything we expect from a IaC framework: open source, cloud-agnostic provisioning tool that supported immutable infrastructure, a declarative language, and a client-only architecture.</p> <p> Read More</p> <ul> <li>Why Infrastructure as Code</li> <li>Why Terraform by Gruntwork</li> </ul> Why BeSLab\u2753 <p>AWS Organizations helps you centrally manage and govern your environment as you grow and scale your AWS resources. Using AWS Organizations, you can programmatically create new AWS accounts and allocate resources, group accounts to organize your workflows, apply policies to accounts or groups for governance, and simplify billing by using a  single payment method for all of your accounts.</p> <p> Read More </p> <ul> <li>How it works: AWS Organizations</li> <li>AWS Organizations</li> </ul> Why Open Source Projects\u2753 <p>AWS Identity and Access Management (IAM) enables you to manage access to AWS services and resources securely. Using IAM, you can create and manage AWS users and groups, and use permissions to allow and deny their access to AWS resources.</p> <ul> <li>Integration and Fine-grained access control with almost every AWS service and its resources.</li> <li>Multi-factor authentication for highly privileged users.</li> <li>Analyze, monitor and audit access.</li> </ul> <p> Read More </p> <ul> <li>How it works: AWS IAM</li> <li>AWS Identity and Access Management (IAM)</li> </ul> Why Open Source LLMs\u2753 <p>Amazon Virtual Private Cloud (Amazon VPC) is a service that lets you launch AWS resources in a logically isolated virtual network that you define. You have complete control over your virtual networking environment, including selection of your own IP address range, creation of subnets, and configuration of route tables and network gateways. You can use both IPv4 and IPv6 for most resources in your virtual private cloud, helping to ensure secure and easy access to resources and applications.</p> <p> Read More </p> <ul> <li>How it works: AWS Networking</li> <li>AWS Virtual Private Cloud</li> </ul> Why S3\u2753 <p>Amazon Simple Storage Service (Amazon S3) is an object storage service that offers industry-leading scalability, data availability, security, and performance.  This means customers of all sizes and industries can use it to store and protect any amount of data for a range of use cases, such as data lakes, websites, mobile applications, backup and restore, archive, enterprise applications, IoT devices, and big data analytics. Amazon S3 provides easy-to-use management features so you can organize your data and configure finely-tuned access controls to meet your specific business, organizational, and compliance requirements. Amazon S3 is designed for 99.999999999% (11 9's) of durability, and stores data for millions of applications for companies all around the world.</p> <p> Read More </p> <ul> <li>How it works: AWS Storage</li> <li>AWS S3</li> </ul>"},{"location":"concepts/what-is-ossverse/","title":"What is OSSVerse?","text":"<p>OSSVerse is an open source Marketplace. It is conceptualized as an eco system project comprising of multiple platforms. It is an adaptation of ONDC and Beckn protocol for open source software service delivery . OSSVerse leverages BeSecure(BeS) for delivering open source software security assurance services. OSSVerse aims to establish an open network of OASPs for businesses that will offer trustworthy and reliable open source software assurance services.</p>"},{"location":"concepts/what-is-ossverse/#key-stakeholders","title":"Key Stakeholders","text":"<p>A Trustworthy Marketplace for Open-Source Assurance Service Providers (OASP) backed by a thriving open-source security community. Affordable and timely access to vendor neutral security services for organizations producing and consuming open-source. OASP led open source assurance service delivery would give full control over their open source components</p> <ul> <li> <p> Open Source Model Producers (Individuals &amp; Organizations): Create and share open source models.</p> </li> <li> <p> Open Source Model Consumers (Organizations): Consume and request for assurance services of open source models.</p> </li> <li> <p> Open Source Model Distributors (Platforms &amp; Organizations): Distribute the sharing of open-source models along with the proof of attestation of models OASP.</p> </li> <li> <p> Open Source Marketplace operator/consortia: Deploys people resources to maintain and operate marketplace and responsible for the governance marketplace.</p> </li> <li> <p> Open Source Assurance Service Provider (OASP): An organization that provides security assurance support services like risk assessment, a hardened version of the OSS artifact, remediation of one or more specific vulnerabilities. Provide Validation, Verification, Attestation &amp; Support Service. Set up dedicated remediated pipelines for organizations, Validate models, create model cards &amp; ensure quality/security.</p> </li> <li> <p> Security Experts &amp; Freelancers: Offering open-source security assessments and support services.</p> </li> </ul>"},{"location":"concepts/what-is-ossverse/#video-presentation","title":"Video Presentation","text":"<p>Check out this intro video  that explains what OSSVerse is in less than 5 minutes:</p>"},{"location":"concepts/what-ossverse-can-do-for-you/","title":"What can OSSVerse do for you?","text":"<p>Still not convinced? Check out the following sections which describe what OSSVerse can bring on the table depending on the type of participant in the decentralized marketplace.</p>"},{"location":"concepts/what-ossverse-can-do-for-you/#ossverse-for-open-source-projects-and-ml-model-consumers","title":"OSSVerse for Open Source Projects and ML Model Consumers","text":"Accelerate development and optimize costs <p>Annual cost savings are a new standard and best practice. Profits are being targeted to business development, regulatory and compliance needs. Resulting in a reduction of pressure on IT and development budgets, granting the opportunity to focus in new features and boost innovation.</p> Modernize applications architecture (loosely coupled and modular) <p>Strategically decompose the monolith into a fine-grained, loosely coupled modular architecture to increase both  development and business agility. When the system architecture is designed to allow teams to test, deploy and change systems without relying on other teams, they require little communication to get the job done.  In other words, both the architecture and the teams are loosely coupled.</p> Innovation - Rapidly adopt new technologies and reduce development time <p>Use Leverage Reference Architecture and for AWS + our libraries to provide a collection of cloud application architecture components to build and deploy faster in the cloud. Building a cloud Landing Zone is complex,  especially since most companies have little or no expertise in this area. And it can take a significant amount  of time to get it right. Leverage a reference architecture to give you an AWS Landing Zone that provides a  consistent and solid \"foundations\" to bootstrap your project in the cloud. The code solution implements the best  AWS Well-Architected Framework practices as well as the battle-tested tech experience and years of knowledge of our contributors.</p> Hours or days, not weeks or months <p>Leverage implements infrastructure as code at all times. We have rolled this out using Terraform, and has been fully proven in AWS and other Terraform providers that are part of our reference architecture like Kubernetes, Helm and Hashicorp Vault. By using the <code>Leverage CLI</code>, our binary will help you to quickly bootstrap your AWS Landing Zone in a matter of hours (or at most a few days).</p>"},{"location":"concepts/what-ossverse-can-do-for-you/#ossverse-for-open-source-projects-and-ml-model-producers","title":"OSSVerse for Open Source Projects and ML Model Producers","text":"It's not just a pile of scripts <p>It's not just another layer of untested, one time and stand-alone developed scripts. The code is modularized and well designed under best practices, our <code>Leverage CLI</code> has both unit and integration tests. While our Terraform code has been extensively E2E tested. Moreover, 100% of the code is yours (to modify, extend, reuse, etc), with no vendor locking and vendor licensing fees. We use the MIT license, so you can take the code, modify it and use it as your private code. All we ask in return is a friendly greeting and that (if possible) consider contributing to binbash Leverage project. Implement Leverage yourself or we  can deploy it for you!</p> DevOps culture and methodologies <p>Team agility and continuous improvements based on feedback loops are some of the main drivers of cloud adoption, and IAC's goal of reducing the frequency of deployment of both infrastructure and applications are some of the most important aspects of DevOps practices. We continue to apply these methodologies to achieve a DevOps first culture. We have experienced and demonstrated their potential and have practiced them in dozens of projects over the past 5 years. The Leverage reference architecture for AWS combines a set of application best practices, technology patterns and a common CI/CD deployment approach through <code>Leverage CLI</code> for all your application environments. As a result, we are pursuing a world-class software delivery performance through optimized collaboration, communication, reliability, stability, scalability and security at ever-decreasing cost and effort.</p> Repeatable, composable and extensible immutable infrastructure <p>The best high-performance development teams create and recreate their development and production environments using infrastructure as code (IaC) as part of their daily development processes. The <code>Leverage CLI</code> allows to build repeatable and immutable infrastructure. So your cloud development, staging and production environments will consistently be the same.</p>"},{"location":"concepts/what-ossverse-can-do-for-you/#ossverse-for-open-source-assurance-service-providers","title":"OSSVerse for Open Source Assurance Service Providers","text":"Provisioning infrastructure as code (Iac) <p>Instead of manually provisioning infrastructure, the real benefits of cloud adoption come from orchestrating infrastructure through code. However, this is really challenging to achieve, there are literally thousands of tiny things and configs to consider and they all seem to take forever. Our experience is that it can take teams up to 24 months to achieve a desired infra state in AWS. By using Leverage you could get your AWS Landing-Zone in few weeks, or your entire AWS Well-Architected based cloud solution within 1 to 3 months (depending on your project complexity needs).</p> We've done it before (don't reinvent the wheel) <p>Often, development teams have similar and recurring requests such as: iam, networking, security, storage,  databases, compute and secret management, etc. binbash Leverage has been proven in dozen of project to create software-defined (IaC) AWS environments.</p> Best practices baked in the code <p>Leverage provides IaC reference architecture for AWS hosted applications infrastructure. This is baked into the code as a combination of the best AWS Well-Architected framework practices and the experience of having successfully orchestrated many customers to AWS cloud.</p> On-demand infra deployment <p>Leverage provides your DevOps, Cloud, SRE and Development teams with the ability to provision on-demand infrastructure, granting that it will meet the rigorous security requirements of modern cloud native best practices.  It fully implements AWS Well-Architected Framework (WAF) and best DevOps practices, including practices, including collaboration, version control, CI/CD, continuous testing, cloud infrastructure and losely couple architectures.</p> Easier to support and maintain <p>Leverage IaC approach significantly reduce your AWS infra deployment, config and support burden and reduce risk.  Our code backed provisioning has been rigorously tested many times, eliminating the possibility of manual errors.  Because the entire infrastructure is deployed from the same proven code, the consistency your cloud environments will simplify your setup and maintenance. Use the versioned code to iterate and improve, extend or compose your internal processes as your cloud operating model evolves.</p> There is no vendor lock-in. You own the solution <p>With Leverage you own 100% of the code with no lock-in clauses. If you choose to leave Leverage, you will still  have your entire AWS cloud infrastructure that you can access and manage. If you drop Leverage, you will still have your entire cloud native infrastructure code (Terraform, Helm, Ansible, Python). It\u2019s 100% Open Source on GitHub and is free to use with no strings attached under MIT license  (no licensing fees), and you are free to commercially and privately use, distribute and modify.</p>"},{"location":"concepts/why-ossverse/","title":"Why OSSVerse?","text":""},{"location":"concepts/why-ossverse/#state-of-open-source-in-enterprise","title":"State of open source in enterprise","text":"<p>Many organizations lack internal expertise to effectively assure and remediate open-source models, creating a demand for external services such as Open-source Assurance Service Providers (OASP). Organizations require  timely support for open-source models, datasets, and projects.</p> <p>Did you know?</p> <p>The widespread adoption of OSS (open source software) across industries has brought immense innovation but also unique security challenges. One of the barriers to OSS adoption is the lack of Trust.! </p>"},{"location":"concepts/why-ossverse/#the-solution","title":"The solution","text":"<p>A Trustworthy Marketplace for Open-Source Assurance Service Providers (OASP) backed by a thriving open-source security community. Affordable and timely access to vendor neutral security services for organizations producing and consuming open-source. OASP led open source assurance service delivery would give full control over their open source components</p>"},{"location":"concepts/why-ossverse/#what-are-the-considerations-while-adopting-an-open-source-first-strategy","title":"What are the considerations while adopting an Open source first Strategy?","text":"Supply chain &amp; Security Risk <p>More content to be added here.</p> Limited Control and support <p>More content to be added here.</p> Forking Cost <p>More content to be added here.</p> Incomplete Security <p>More content to be added here.</p> Uncertain Reliability <p>More content to be added here.</p> Fragmented Knowledge <p>More content to be added here.</p>"},{"location":"concepts/why-ossverse/#what-is-our-solution","title":"What is our solution?","text":"Figure: Decentralized marketplace interactions between stakeholders."},{"location":"getting-started/","title":"Index","text":""},{"location":"getting-started/#try-leverage","title":"Try Leverage","text":""},{"location":"getting-started/#before-you-begin","title":"Before you begin","text":"<p>The objective of this guide is to introduce you to our binbash Leverage Reference Architecture for AWS workflow  through the complete deployment of a basic landing zone configuration.</p> <p>The Leverage Landing Zone is the smallest possible fully functional configuration.  It lays out the base infrastructure required to manage the environment: billing and financial management, user management, security enforcement, and shared services and resources. Always following the best practices layed out by the AWS Well-Architected Framework  to ensure quality and to provide a solid base to build upon. This is the starting point from which any Leverage user can and will develop all the features and capabilities they may require to satisfy their specific needs.</p> <p></p> Figure: Leverage Landing Zone architecture components diagram."},{"location":"getting-started/#about-this-guide","title":"About this guide","text":"<p>In this guide you will learn how to:</p> <ul> <li> Create and configure your AWS account.</li> <li> Work with the Leverage CLI to manage your credentials, infrastructure and the whole Leverage stack.</li> <li> Prepare your local environment to manage a Leverage project.</li> <li> Orchestrate the project's infrastructure.</li> <li> Configure your users' credentials to interact with the project.</li> </ul> <p>Upon completion of this guide you will gain an understanding of the structure of a project as well as familiarity with the tooling used to manage it.</p> <p>To begin your journey into creating your first Leverage project, continue to the next section of the guide where you will start by setting up your AWS account.</p>"},{"location":"getting-started/add-aws-accounts/","title":"Add more AWS Accounts","text":""},{"location":"getting-started/add-aws-accounts/#brief","title":"Brief","text":"<p>You can add new AWS accounts to your Leverage project by following the steps in this page.</p> <p>Important</p> <p>In the examples below, we will be using <code>apps-prd</code> as the account we will be adding and it will be created in the <code>us-east-1</code> region.</p>"},{"location":"getting-started/add-aws-accounts/#create-the-new-account-in-your-aws-organization","title":"Create the new account in your AWS Organization","text":"<ol> <li>Go to <code>management/global/organizations</code>.</li> <li>Edit the <code>locals.tf</code> file to add the account to the local <code>accounts</code> variable.     <pre><code>    accounts = {\n    ...\n    ...\n        apps-prd = {\n            email     = \"aws+apps-prd@yourcompany.com\",\n            parent_ou = \"apps\"\n        }\n    }\n</code></pre>     Note that the <code>apps</code> organizational unit (OU) is being used as the parent OU of the new account. If you need to use a new OU you can add it to <code>organizational_units</code> variable in the same file.</li> <li>Run the Terraform workflow to apply the new changes. Typically that would be this:     <pre><code>leverage terraform init\nleverage terraform apply\n</code></pre></li> </ol> <p>Authentication error</p> <p>Note this layer was first applied before using the boostrap user. Now, that we are working with SSO, credentials have changed. So, if this is the first account you add you'll probably get this error applying: \"Error: error configuring S3 Backend: no valid credential sources for S3 Backend found.\" In this case running <code>leverage tf init -reconfigure</code> will fix the issue.</p> <ol> <li> <p>Add the new account to the <code>&lt;project&gt;/config/common.tfvars</code> file. The new account ID should have been displayed in the output of the previous step, e.g.:    <pre><code>aws_organizations_account.accounts[\"apps-prd\"]: Creation complete after 14s [id=999999999999]\n</code></pre> Note the id, <code>999999999999</code>.</p> <p>...so please grab it from there and use it to update the file as shown below: <pre><code>accounts = {\n\n[...]\n\n    apps-prd = {\n        email = \"&lt;aws+apps-prd@yourcompany.com&gt;\",\n        id    = \"&lt;add-the-account-id-here&gt;\"\n    }\n}\n</code></pre> 5. Since you are using SSO in this project, permissions on the new account must be granted before we can move forward. Add the right permissions to the <code>management/global/sso/account_assignments.tf</code> file. For the example: <pre><code> # -------------------------------------------------------------------------\n # apps-prd account\n # -------------------------------------------------------------------------\n {\n   account             = var.accounts.apps-prd.id,\n   permission_set_arn  = module.permission_sets.permission_sets[\"Administrator\"].arn,\n   permission_set_name = \"Administrator\",\n   principal_type      = local.principal_type_group\n   principal_name      = local.groups[\"administrators\"].name\n },\n {\n   account             = var.accounts.apps-prd.id,\n   permission_set_arn  = module.permission_sets.permission_sets[\"DevOps\"].arn,\n   permission_set_name = \"DevOps\",\n   principal_type      = local.principal_type_group\n   principal_name      = local.groups[\"devops\"].name\n },\n</code></pre> Note your needs can vary, these permissions are just an example, please be careful with what you are granting here.</p> <p>Apply these changes: <pre><code>leverage terraform apply\n</code></pre> And you must update your AWS config file accordingly by running this: <pre><code>leverage aws configure sso\n</code></pre></p> </li> </ol> <p>Good! Now you are ready to create the initial directory structure for the new account. The next section will guide through those steps.</p>"},{"location":"getting-started/add-aws-accounts/#create-and-deploy-the-layers-for-the-new-account","title":"Create and deploy the layers for the new account","text":"<p>In this example we will create the <code>apps-prd</code> account structure by using the <code>shared</code> as a template.</p>"},{"location":"getting-started/add-aws-accounts/#create-the-initial-directory-structure-for-the-new-account","title":"Create the initial directory structure for the new account","text":"<ol> <li>Ensure you are at the root of this repository</li> <li>Now create the directory structure for the new account:     <pre><code>mkdir -p apps-prd/{global,us-east-1}\n</code></pre></li> <li>Set up the config files:<ol> <li>Create the config files for this account:      <pre><code>cp -r shared/config apps-prd/config\n</code></pre></li> <li>Open <code>apps-prd/config/backend.tfvars</code> and replace any occurrences of <code>shared</code> with <code>apps-prd</code>.</li> <li>Do the same with <code>apps-prd/config/account.tfvars</code></li> </ol> </li> </ol>"},{"location":"getting-started/add-aws-accounts/#create-the-terraform-backend-layer","title":"Create the Terraform Backend layer","text":"<ol> <li> <p>Copy the layer from an existing one:     <pre><code>cp -r shared/us-east-1/base-tf-backend apps-prd/us-east-1/base-tf-backend\n</code></pre></p> <p>Info</p> <p>If the source layer was already initialized you should delete the previous Terraform setup using <code>sudo rm -rf .terraform*</code> in the target layer's directory, e.g. <code>rm -rf apps-prd/us-east-1/base-tf-backend/.terraform*</code></p> </li> <li> <p>Go to the <code>apps-prd/us-east-1/base-tf-backend</code> directory, open the <code>config.tf</code> file and comment the S3 backend block. E.g.:     <pre><code>#backend \"s3\" {\n#    key = \"shared/tf-backend/terraform.tfstate\"\n#}\n</code></pre>     We need to do this for the first apply of this layer.</p> </li> <li> <p>Now run the Terraform workflow to initialize and     apply this layer. The flag <code>--skip-validation</code> is needed here since the bucket does not yet exist.     <pre><code>leverage terraform init --skip-validation\nleverage terraform apply\n</code></pre></p> </li> <li>Open the <code>config.tf</code> file again uncommenting the block commented before and replacing <code>shared</code> with <code>apps-prd</code>. E.g.:     <pre><code>backend \"s3\" {\n    key = \"apps-prd/tf-backend/terraform.tfstate\"\n}\n</code></pre></li> <li>To finish with the backend layer, re-init to move the <code>tfstate</code> to the new location. Run:     <pre><code>leverage terraform init\n</code></pre>     Terraform will detect that you are trying to move from a local to a remote state and will ask for confirmation.     <pre><code>Initializing the backend...\nAcquiring state lock. This may take a few moments...\nDo you want to copy existing state to the new backend?\n    Pre-existing state was found while migrating the previous \"local\" backend to the\n    newly configured \"s3\" backend. No existing state was found in the newly\n    configured \"s3\" backend. Do you want to copy this state to the new \"s3\"\n    backend? Enter \"yes\" to copy and \"no\" to start with an empty state.\n\n    Enter a value: \n</code></pre>     Enter <code>yes</code> and hit enter.</li> </ol>"},{"location":"getting-started/add-aws-accounts/#create-the-security-base-layer","title":"Create the <code>security-base</code> layer","text":"<ol> <li> <p>Copy the layer from an existing one:     From the repository root run:      <pre><code>cp -r shared/us-east-1/security-base apps-prd/us-east-1/security-base\n</code></pre></p> <p>Info</p> <p>If the source layer was already initialized you should delete the previous Terraform setup using <code>sudo rm -rf .terraform*</code> in the target layer's directory, e.g. <code>rm -rf apps-prd/us-east-1/security-base/.terraform*</code></p> </li> <li> <p>Go to the <code>apps-prd/us-east-1/security-base</code> directory and open the <code>config.tf</code> file replacing any occurrences of <code>shared</code> with <code>apps-prd</code>     E.g. this line should be:     <pre><code>backend \"s3\" {\n    key = \"apps-prd/security-base/terraform.tfstate\"\n}\n</code></pre></p> </li> <li> <p>Init and apply the layer</p> <pre><code>leverage tf init\nleverage tf apply\n</code></pre> </li> </ol>"},{"location":"getting-started/add-aws-accounts/#create-the-network-layer","title":"Create the <code>network</code> layer","text":"<ol> <li> <p>Copy the layer from an existing one:     From the root of the repository run this:      <pre><code>cp -r shared/us-east-1/base-network apps-prd/us-east-1/base-network\n</code></pre></p> <p>Info</p> <p>If the source layer was already initialized you should delete the previous Terraform setup using <code>sudo rm -rf .terraform*</code> in the target layer's directory, e.g. <code>rm -rf apps-prd/us-east-1/base-network/.terraform*</code></p> </li> <li> <p>Go to the <code>apps-prd/us-east-1/base-network</code> directory and open the <code>config.tf</code> file replacing any occurrences of <code>shared</code> with <code>apps-prd</code>. E.g. this line should be:     <pre><code>backend \"s3\" {\n    key = \"apps-prd/network/terraform.tfstate\"\n}\n</code></pre></p> </li> <li> <p>Open the file <code>locals.tf</code> and set the new account's CIDRs.     <pre><code>vpc_cidr_block = \"172.19.0.0/20\"\nazs = [\n    \"${var.region}a\",\n    \"${var.region}b\",\n    #\"${var.region}c\",\n    #\"${var.region}d\",\n]\n\nprivate_subnets_cidr = [\"172.19.0.0/21\"]\nprivate_subnets = [\n    \"172.19.0.0/23\",\n    \"172.19.2.0/23\",\n    #\"172.19.4.0/23\",\n    #\"172.19.6.0/23\",\n]\n\npublic_subnets_cidr = [\"172.19.8.0/21\"]\npublic_subnets = [\n    \"172.19.8.0/23\",\n    \"172.19.10.0/23\",\n    #\"172.19.12.0/23\",\n    #\"172.19.14.0/23\",\n]\n</code></pre>     Note here only two AZs are enabled, if needed uncomment the other ones in the three structures.</p> <p>Do not overlap CIDRs!</p> <p>Be careful when chosing CIDRs. Avoid overlaping CIDRs between accounts. If you need a reference on how to chose the right CIDRs, please see here.</p> <p>Calculate CIDRs</p> <p>To calculate CIDRs you can check this playbook.</p> </li> <li> <p>Init and apply the layer     <pre><code>leverage tf init\nleverage tf apply\n</code></pre></p> </li> <li> <p>Create the VPC Peering between the new account and the VPC of the Shared account. Edit file <code>shared/us-east-1/base-network/config.tf</code> and add provider and remote state for the created account.     <pre><code>provider \"aws\" {\n    alias                   = \"apps-prd\"\n    region                  = var.region\n    profile                 = \"${var.project}-apps-prd-devops\"\n}\n\ndata \"terraform_remote_state\" \"apps-prd-vpcs\" {\n    for_each = {\n    for k, v in local.apps-prd-vpcs :\n    k =&gt; v if !v[\"tgw\"]\n    }\n\n    backend = \"s3\"\n\n    config = {\n    region  = lookup(each.value, \"region\")\n    profile = lookup(each.value, \"profile\")\n    bucket  = lookup(each.value, \"bucket\")\n    key     = lookup(each.value, \"key\")\n    }\n}\n</code></pre>     Edit file <code>shared/us-east-1/base-network/locals.tf</code> and under      <pre><code>#\n# Data source definitions\n#\n</code></pre>     ...add the related structure:     <pre><code>#\n# Data source definitions\n#\napps-prd-vpcs = {\n    apps-prd-base = {\n    region  = var.region\n    profile = \"${var.project}-apps-prd-devops\"\n    bucket  = \"${var.project}-apps-prd-terraform-backend\"\n    key     = \"apps-prd/network/terraform.tfstate\"\n    tgw     = false\n    }\n}\n</code></pre>     Edit file <code>shared/us-east-1/base-network/vpc_peerings.tf</code> (if this is your first added account the file won\u00b4t exist, please crate it) and add the peering definition:     <pre><code>#\n# VPC Peering: AppsPrd VPC =&gt; Shared VPC\n#\nmodule \"vpc_peering_apps_prd_to_shared\" {\n    source = \"github.com/binbashar/terraform-aws-vpc-peering.git?ref=v6.0.0\"\n\n    for_each = {\n    for k, v in local.apps-prd-vpcs :\n    k =&gt; v if !v[\"tgw\"]\n    }\n\n    providers = {\n    aws.this = aws\n    aws.peer = aws.apps-prd\n    }\n\n    this_vpc_id = module.vpc.vpc_id\n    peer_vpc_id = data.terraform_remote_state.apps-prd-vpcs[each.key].outputs.vpc_id\n\n    this_rts_ids = concat(module.vpc.private_route_table_ids, module.vpc.public_route_table_ids)\n    peer_rts_ids = concat(\n    data.terraform_remote_state.apps-prd-vpcs[each.key].outputs.public_route_table_ids,\n    data.terraform_remote_state.apps-prd-vpcs[each.key].outputs.private_route_table_ids\n    )\n\n    auto_accept_peering = true\n\n    tags = merge(local.tags, {\n    \"Name\"             = \"${each.key}-to-shared\",\n    \"PeeringRequester\" = each.key,\n    \"PeeringAccepter\"  = \"shared\"\n    })\n    }\n</code></pre>     Apply the changes (be sure to CD into <code>shared/us-east-1/base-network</code> layer for doing this):     <pre><code>leverage terraform init\nleverage terraform apply\n</code></pre></p> </li> </ol>"},{"location":"getting-started/add-aws-accounts/#done","title":"Done!","text":"<p>That should be it. At this point you should have the following:</p> <ol> <li>A brand new AWS account in your AWS organization.</li> <li>Working configuration files for both existing layers and any new layer you add in the future.</li> <li>A remote Terraform State Backend for this new account.</li> <li>Roles and policies (SSO) that are necessary to access the new account.</li> <li>The base networking resources ready to host your compute services.</li> <li>The VPC peerings between the new account and shared</li> </ol>"},{"location":"getting-started/add-aws-accounts/#next-steps","title":"Next steps","text":"<p>Now you have a new account created, so what else?</p> <p>To keep creating infra on top of this binbash Leverage Landing Zone with this new account added, please check:</p> <ul> <li>  Check common use cases in Playbooks</li> <li>  Review the binbash Leverage architecture</li> <li>  Go for EKS!</li> </ul>"},{"location":"getting-started/aws-account-setup/","title":"Creating your AWS Management account","text":""},{"location":"getting-started/aws-account-setup/#create-the-first-aws-account","title":"Create the first AWS account","text":"<p>First and foremost you'll need to create an AWS account for your project.</p> <p>Attention</p> <p>Note this will be your management account and has to be called <code>&lt;project-name&gt;-management</code>.</p> <p>E.g. if your project is called <code>binbash</code> then your account should be <code>binbash-management</code>.</p> <p>Follow the instructions here.</p> <p>This will be the management account for your AWS Organization and the email address you use for signing up will be the root user of this account -- you can see this user represented in the architecture diagram.</p> <p>Since the root user is the main access point to your account it is strongly recommended that you keep its credentials (email, password) safe by following AWS best practices.</p> <p>Tip</p> <pre><code>To protect your management account, [enabling Multi Factor Authentication](https://docs.aws.amazon.com/IAM/latest/UserGuide/id_root-user.html#id_root-user_manage_mfa) is **highly** encouraged. Also, reviewing the [account's billing setup](https://console.aws.amazon.com/billing/home?#/account) is always a good idea before proceeding.\n</code></pre> <p>For more details on setting up your AWS account:  Organization account setup guide</p>"},{"location":"getting-started/aws-account-setup/#create-a-bootstrap-user-with-temporary-administrator-permissions","title":"Create a bootstrap user with temporary administrator permissions","text":"<p>Leverage needs a user with temporary administrator permissions in order to deploy the initial resources that will form the foundations you will then use to keep building on. That initial deployment is called the bootstrap process and thus the user required for that is called \"the bootstrap user\".</p> <p>To create that user, navigate to the IAM page and create a user named <code>mgmt-org-admin</code> following steps 2 and 3 of this leverage doc.</p> <p>Info</p> <pre><code>Bear in mind that the page for creating users may change from time to time but the key settings for configuring the bootstrap user are the following:\n\n* It must be an IAM user (we won't be using IAM Identity Center for this)\n* Password can be auto-generated\n* It requires admin privileges which you can achieve by directly attaching the `AdministratorAccess` policy to it\n* There's no need to add the user to any group as it is only a temporary user\n</code></pre> <p>Usually the last step of the user creation should present you the following information:</p> <ul> <li>Console sign-in URL</li> <li>User name</li> <li>Console password</li> </ul> <p>Make a note of all of these and keep them in a safe place as you will need them in the following steps.</p> <p>Info</p> <pre><code>If you are only getting the bootstrap user credentials for someone else in your team or\nin Binbash's team, then please share that using a secure way (e.g. password management\nservice, GPG keys, etc).\n</code></pre> <p>Info</p> <pre><code>If user was set up with the option \"Force to change password on first login\", you should log into the console to do so.\n</code></pre>"},{"location":"getting-started/aws-account-setup/#next-steps","title":"Next steps","text":"<p>You have successfully created and configured the AWS account for your Leverage project. From now on, almost all interactions with the AWS environment (with few notable exceptions) will be performed via Leverage.</p> <p>Next, you will setup all required dependencies to work on a Leverage project in your local machine.</p>"},{"location":"getting-started/enabling-sso/","title":"Configure SSO settings","text":""},{"location":"getting-started/enabling-sso/#enable-sso","title":"Enable SSO","text":"<p>Let's start by configuring SSO settings. Open this file: <code>&lt;your_project&gt;/config/common.tfvars</code> and update the following lines: <pre><code>sso_enabled   = false\nsso_start_url = \"https://bbleverage.awsapps.com/start\"\n</code></pre></p> <p>Change <code>sso_enabled</code> to <code>true</code> as follows to enable SSO support: <pre><code>sso_enabled   = true\n</code></pre></p> <p>Now you need to set the <code>sso_start_url</code> with the right URL. To find that, navigate here: <code>https://us-east-1.console.aws.amazon.com/singlesignon/home</code> -- you should be already logged in to the Management account for this to work. You should see a \"Settings summary\" panel on the right of the screen that shows the \"AWS access portal URL\". Copy that and use it to replace the value in the <code>sso_start_url</code> entry. Below is an example just for reference: <pre><code>sso_start_url = \"https://d-xyz01234567.awsapps.com/start\"\n</code></pre></p> <p>Customize the AWS access portal URL</p> <p>The 'AWS access portal URL' can be customized to use a more friendly name. Check the official documentation for that.</p> <p>Further info on configuring SSO</p> <p>There is more information on how to configure SSO here.</p>"},{"location":"getting-started/enabling-sso/#update-backend-profiles-in-the-management-account","title":"Update backend profiles in the management account","text":"<p>It's time to set the right profile names in the backend configuration files. Open this file: <code>management/config/backend.tfvars</code> and change the <code>profile</code> value from this: <pre><code>profile = \"me-bootstrap\"\n</code></pre> To this: <pre><code>profile = \"me-management-oaar\"\n</code></pre> Please note that in the examples above my short project name is <code>me</code> which is used as a prefix and it's the part that doesn't get replaced.</p>"},{"location":"getting-started/enabling-sso/#activate-your-sso-user-and-set-up-your-password","title":"Activate your SSO user and set up your password","text":"<p>The SSO users you created when you provisioned the SSO layer need to go through an email activation procedure.</p> <p>The user is the one you set in the <code>project.yaml</code> file at the beginning, in this snippet:</p> <pre><code>users:\n- first_name: the-name\n  last_name: the-last-name\n  email: user@domain.co\n  groups:\n  - administrators\n  - devops\n</code></pre> <p>To activate the user find the instructions here.</p> <p>Once SSO user's have been activated, they will need to get their initial password so they are able to log in. Check out the steps for that here.</p> <p>Basically:</p> <ul> <li>Log into your <code>sso_start_url</code> address</li> <li>Ingress your username (the user email)</li> <li>Under Password, choose Forgot password.</li> <li>Type in the code shown in the screen</li> <li>A reset password email will be sent</li> <li>Follow the link and reset your password</li> <li>Now, in the same URL as before, log in with the new credentials</li> <li>You will be prompted to create an MFA, just do it.</li> </ul>"},{"location":"getting-started/enabling-sso/#configure-the-cli-for-sso","title":"Configure the CLI for SSO","text":"<p>Almost there. Let's try the SSO integration now.</p>"},{"location":"getting-started/enabling-sso/#configure-your-sso-profiles","title":"Configure your SSO profiles","text":"<p>Since this is your first time using that you will need to configure it by running this: </p> <pre><code>leverage aws configure sso\n</code></pre> <p>Follow the wizard to get your AWS config file created for you. There is more info about that here.</p>"},{"location":"getting-started/enabling-sso/#verify-on-a-layer-in-the-management-account","title":"Verify on a layer in the management account","text":"<p>To ensure that worked, let's run a few commands to verify:</p> <ol> <li>We'll use <code>sso</code> for the purpose of this example</li> <li>Move to the <code>management/global/sso</code> layer</li> <li>Run: <code>leverage tf plan</code></li> <li>You should get this error: \"Error: error configuring S3 Backend: no valid credential sources for S3 Backend found.\"</li> <li>This happens because so far you have been running Terraform with a different AWS profile (the bootstrap one). Luckily the fix is simple, just run this: <code>leverage tf init -reconfigure</code>. Terraform should reconfigure the AWS profile in the <code>.terraform/terraform.tfstate</code> file.</li> <li>Now try running that <code>leverage tf plan</code> command again</li> <li>This time it should succeed, you should see the message: <code>No changes. Your infrastructure matches the configuration.</code></li> </ol> <p>Note if you still have the same error, try clearing credentials with:</p> <pre><code>leverage aws sso logout &amp;&amp; leverage aws sso login\n</code></pre>"},{"location":"getting-started/enabling-sso/#next-steps","title":"Next steps","text":"<p>You successfully enabled SSO.</p> <p>Next, you will orchestrate the remaining accounts, <code>security</code> and <code>shared</code>.</p>"},{"location":"getting-started/leverage-project-setup/","title":"Create a Leverage project","text":"<p>A Leverage project starts with a simple project definition file that you modify to suit your needs. That file is then used to render the initial directory layout which, at the end of this guide, will be your reference architecture. Follow the sections below to begin with that.</p> <p>The account's name will be given by your project's name followed by <code>-management</code>, since Leverage uses a suffix naming system to differentiate between the multiple accounts of a project. For this guide we'll stick to calling the project <code>MyExample</code> and so, the account name will be <code>myexample-management</code>. </p> <p>Along the same line, we'll use the <code>example.com</code> domain for the email address used to register the account. Adding a <code>-aws</code> suffix to the project's name to indicate that this email address is related to the project's AWS account, we end up with a registration email that looks like <code>myexample-aws@example.com</code>.</p> <p>Email addresses for AWS accounts.</p> <pre><code>Each AWS account requires having a unique email address associated to it. The Leverage Reference Architecture for AWS makes use of multiple accounts to better manage the infrastructure, as such, you will need different addresses for each one. Creating a new email account for each AWS is not a really viable solution to this problem, a better approach is to take advantage of mail services that support aliases. For information regarding how this works: [:books: Email setup for your AWS account.](/user-guide/ref-architecture-aws/features/organization/configuration/#pre-requisites)\n</code></pre>"},{"location":"getting-started/leverage-project-setup/#create-the-project-directory","title":"Create the project directory","text":"<p>Each Leverage project lives in its own working directory. Create a directory for your project as follows: <pre><code>mkdir myexample\ncd myexample\n</code></pre></p>"},{"location":"getting-started/leverage-project-setup/#initialize-the-project","title":"Initialize the project","text":"<p>Create the project definition file by running the following command: <pre><code>$ leverage project init\n[18:53:24.407] INFO     Project template found. Updating.                                                                                              \n[18:53:25.105] INFO     Finished updating template.                                                                                                    \n[18:53:25.107] INFO     Initializing git repository in project directory.                                                                              \n[18:53:25.139] INFO     No project configuration file found. Dropping configuration template project.yaml.                                             \n[18:53:25.143] INFO     Project initialization finished.\n</code></pre></p> <p>The command above should create the project definition file (<code>project.yaml</code>) and should initialize a <code>git</code> repository in the current working directory. This is important because Leverage projects by-design rely on specific <code>git</code> conventions and also because it is assumed that you will want to keep your infrastructure code versioned.</p>"},{"location":"getting-started/leverage-project-setup/#modify-the-project-definition-file","title":"Modify the project definition file","text":"<p>Open the <code>project.yaml</code> file and fill in the required information.</p> <p>Typically the placeholder values between <code>&lt;</code> and <code>&gt;</code> symbols are the ones you would want to edit however you are welcome to adjust any other values to suit your needs.</p> <p>For instance, the following is a snippet of the <code>project.yaml</code> file in which the values for <code>project_name</code> and <code>short_name</code> have been set to <code>example</code> and <code>ex</code> respectively: <pre><code>project_name: example\nshort_name: ex\nprimary_region: us-east-1\nsecondary_region: us-west-2\n...\n</code></pre></p> <p>The <code>project_name</code> field only accepts lowercase alphanumeric characters and allows hyphens('-'). For instance, valid names could be 'example' or 'leveragedemo' or 'example-demo' </p> <p>The <code>short_name</code> field only accepts 2 to 4 lowercase alpha characters. For instance, valid names could be 'exam or 'leve or 'ex </p> <p>We typically use as 1ry <code>us-east-1</code> and 2ry <code>us-west-2</code> as our default regions for the majority of our projects. However, please note that these regions may not be the most fitting choice for your specific use case. For detailed guidance, we recommend following these provided guidelines.</p> <p>Another example is below. Note that the <code>management</code>, <code>security</code>, and <code>shared</code> accounts have been updated with slightly different email addresses (actually <code>aws+security@example.com</code> and <code>aws+shared@example.com</code> are email aliases of <code>aws@example.com</code> which is a convenient trick in some cases): <pre><code>...\norganization:\n  accounts:\n  - name: management\n    email: aws@example.com\n  - name: security\n    email: aws+security@example.com\n  - name: shared\n    email: aws+shared@example.com\n...\n</code></pre></p> <p>Finally, here's another example snippet that shows how you can define users and assign them to groups: <pre><code>...\nusers:\n- first_name: Jane\n  last_name: Doe\n  email: jane.doe@example.com\n  groups:\n  - administrators\n  - devops\n- first_name: Foo\n  last_name: Bar\n  email: foo.bar@example.com\n  groups:\n  - devops\n...\n</code></pre></p> <p>Note these users will be the ones used later for SSO access.</p> <p>The project definition file includes other entries but the ones shown above are the most frequently updated.</p>"},{"location":"getting-started/leverage-project-setup/#configure-bootstrap-credentials","title":"Configure \"bootstrap\" credentials","text":"<p>To be able to interact with your AWS environment you first need to configure the credentials to enable AWS CLI to do so. Provide the keys obtained in the previous account creation step to the command by any of the available means.</p> ManuallyFile selectionProvide file in command <p><pre><code>leverage credentials configure --type BOOTSTRAP\n</code></pre> <pre><code>[09:37:17.530] INFO     Loading configuration file.\n[09:37:18.477] INFO     Loading project environment configuration file.\n[09:37:20.426] INFO     Configuring bootstrap credentials.\n&gt; Select the means by which you'll provide the programmatic keys: Manually\n&gt; Key: AKIAU1OF18IXH2EXAMPLE\n&gt; Secret: ****************************************\n[09:37:51.638] INFO     Bootstrap credentials configured in: /home/user/.aws/me/credentials\n[09:37:53.497] INFO     Fetching management account id.\n[09:37:53.792] INFO     Updating project configuration file.\n[09:37:55.344] INFO     Skipping assumable roles configuration.\n</code></pre></p> <p><pre><code>leverage credentials configure --type BOOTSTRAP\n</code></pre> <pre><code>[09:37:17.530] INFO     Loading configuration file.\n[09:37:18.477] INFO     Loading project environment configuration file.\n[09:37:20.426] INFO     Configuring bootstrap credentials.\n&gt; Select the means by which you'll provide the programmatic keys: Path to an access keys file obtained from AWS\n&gt; Path to access keys file: ../bootstrap_accessKeys.csv\n[09:37:51.638] INFO     Bootstrap credentials configured in: /home/user/.aws/me/credentials\n[09:37:53.497] INFO     Fetching management account id.\n[09:37:53.792] INFO     Updating project configuration file.\n[09:37:55.344] INFO     Skipping assumable roles configuration.\n</code></pre></p> <p><pre><code>leverage credentials configure --type BOOTSTRAP --credentials-file ../bootstrap_accessKeys.csv\n</code></pre> <pre><code>[09:37:17.530] INFO     Loading configuration file.\n[09:37:18.477] INFO     Loading project environment configuration file.\n[09:37:20.426] INFO     Configuring bootstrap credentials.\n[09:37:51.638] INFO     Bootstrap credentials configured in: /home/user/.aws/me/credentials\n[09:37:53.497] INFO     Fetching management account id.\n[09:37:53.792] INFO     Updating project configuration file.\n[09:37:55.344] INFO     Skipping assumable roles configuration.\n</code></pre></p> <p>More information on <code>credentials configure</code></p> <p>During the credentials setup, the AWS account id is filled in for us in the project configuration file.</p> <pre><code>...\norganization:\n  accounts:\n    - name: management\n      email: myexample-aws@example.com\n      id: '000123456789'\n...\n</code></pre>"},{"location":"getting-started/leverage-project-setup/#create-the-configured-project","title":"Create the configured project","text":"<p>Now you will finally create all the infrastructure definition in the project.</p> <pre><code>leverage project create\n</code></pre> <pre><code>[09:40:54.934] INFO     Loading configuration file.\n[09:40:54.950] INFO     Creating project directory structure.\n[09:40:54.957] INFO     Finished creating directory structure.\n[09:40:54.958] INFO     Setting up common base files.\n[09:40:54.964] INFO     Account: Setting up management.\n[09:40:54.965] INFO             Layer: Setting up config.\n[09:40:54.968] INFO             Layer: Setting up base-tf-backend.\n[09:40:54.969] INFO             Layer: Setting up base-identities.\n[09:40:54.984] INFO             Layer: Setting up organizations.\n[09:40:54.989] INFO             Layer: Setting up security-base.\n[09:40:54.990] INFO     Account: Setting up security.\n[09:40:54.991] INFO             Layer: Setting up config.\n[09:40:54.994] INFO             Layer: Setting up base-tf-backend.\n[09:40:54.995] INFO             Layer: Setting up base-identities.\n[09:40:55.001] INFO             Layer: Setting up security-base.\n[09:40:55.002] INFO     Account: Setting up shared.\n[09:40:55.003] INFO             Layer: Setting up config.\n[09:40:55.006] INFO             Layer: Setting up base-tf-backend.\n[09:40:55.007] INFO             Layer: Setting up base-identities.\n[09:40:55.008] INFO             Layer: Setting up security-base.\n[09:40:55.009] INFO             Layer: Setting up base-network.\n[09:40:55.013] INFO     Project configuration finished.\n               INFO     Reformatting terraform configuration to the standard style.\n[09:40:55.743] INFO     Finished setting up project.\n</code></pre> <p>More information on <code>project create</code></p> <p>In this step, the directory structure for the project and all definition files are created using the information from the <code>project.yaml</code> file and checked for correct formatting.</p> <p>You will end up with something that looks like this:</p> MyExample project file structure <p><pre><code>\ud83d\udcc2 myexample\n\u251c\u2500\u2500 \ud83d\udcc4 build.env\n\u251c\u2500\u2500 \ud83d\udcc4 project.yaml\n\u251c\u2500\u2500 \ud83d\udcc2 config\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 \ud83d\udcc4 common.tfvars\n\u251c\u2500\u2500 \ud83d\udcc2 management\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc2 config\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc4 account.tfvars\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 \ud83d\udcc4 backend.tfvars\n|   \u251c\u2500\u2500 \ud83d\udcc2 global\n|   \u2502\u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc2 organizations\n|   \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc4 accounts.tf\n|   \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc4 config.tf\n|   \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc4 delegated_administrator.tf\n|   \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc4 locals.tf\n|   \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc4 organizational_units.tf\n|   \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc4 organization.tf\n|   \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc4 policies_scp.tf\n|   \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc4 policy_scp_attachments.tf\n|   \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc4 service_linked_roles.tf\n|   \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 \ud83d\udcc4 variables.tf\n|   \u2502\u00a0\u00a0 \u2514\u2500\u2500 \ud83d\udcc2 base-identities\n|   \u2502\u00a0\u00a0  \u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc4 account.tf\n|   \u2502\u00a0\u00a0  \u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc4 config.tf\n|   \u2502\u00a0\u00a0  \u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc4 groups.tf\n|   \u2502\u00a0\u00a0  \u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc4 keys\n|   \u2502\u00a0\u00a0  \u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc4 locals.tf\n|   \u2502\u00a0\u00a0  \u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc4 outputs.tf\n|   \u2502\u00a0\u00a0  \u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc4 roles.tf\n|   \u2502\u00a0\u00a0  \u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc4 users.tf\n|   \u2502\u00a0\u00a0  \u00a0\u00a0 \u2514\u2500\u2500 \ud83d\udcc4 variables.tf\n|   \u2514\u2500\u2500 \ud83d\udcc2 us-east-1\n|    \u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc2 base-tf-backend\n|    \u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc4 config.tf\n|    \u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc4 locals.tf\n|    \u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc4 main.tf\n|    \u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 \ud83d\udcc4 variables.tf\n|    \u00a0\u00a0 \u2514\u2500\u2500 \ud83d\udcc2 security-base\n|    \u00a0\u00a0     \u251c\u2500\u2500 \ud83d\udcc4 account.tf\n|    \u00a0\u00a0     \u251c\u2500\u2500 \ud83d\udcc4 config.tf\n|    \u00a0\u00a0     \u2514\u2500\u2500 \ud83d\udcc4 variables.tf\n\u251c\u2500\u2500 \ud83d\udcc2 security\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc2 config\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc4 account.tfvars\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 \ud83d\udcc4 backend.tfvars\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc2 global\n|   |   \u2514\u2500\u2500 \ud83d\udcc2 base-identities\n|   \u2502\u00a0\u00a0  \u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc4 account.tf\n|   \u2502\u00a0\u00a0  \u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc4 config.tf\n|   \u2502\u00a0\u00a0  \u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc4 groups_policies.tf\n|   \u2502\u00a0\u00a0  \u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc4 groups.tf\n|   \u2502\u00a0\u00a0  \u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc4 keys\n|   \u2502\u00a0\u00a0  \u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc4 locals.tf\n|   \u2502\u00a0\u00a0  \u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc4 outputs.tf\n|   \u2502\u00a0\u00a0  \u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc4 role_policies.tf\n|   \u2502\u00a0\u00a0  \u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc4 roles.tf\n|   \u2502\u00a0\u00a0  \u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc4 users.tf\n|   \u2502\u00a0\u00a0  \u00a0\u00a0 \u2514\u2500\u2500 \ud83d\udcc4 variables.tf\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 \ud83d\udcc2 us-east-1\n|    \u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc2 base-tf-backend\n|    \u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc4 config.tf\n|    \u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc4 locals.tf\n|    \u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc4 main.tf\n|    \u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 \ud83d\udcc4 variables.tf\n|    \u00a0\u00a0 \u2514\u2500\u2500 \ud83d\udcc2 security-base\n|    \u00a0\u00a0     \u251c\u2500\u2500 \ud83d\udcc4 account.tf\n|    \u00a0\u00a0     \u251c\u2500\u2500 \ud83d\udcc4 config.tf\n|    \u00a0\u00a0     \u251c\u2500\u2500 \ud83d\udcc4 iam_access_analyzer.tf\n|    \u00a0\u00a0     \u251c\u2500\u2500 \ud83d\udcc4 locals.tf\n\u2502    \u00a0\u00a0     \u2514\u2500\u2500 \ud83d\udcc4 variables.tf\n\u2514\u2500\u2500 \ud83d\udcc2 shared\n    \u251c\u2500\u2500 \ud83d\udcc2 config\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc4 account.tfvars\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 \ud83d\udcc4 backend.tfvars\n    \u251c\u2500\u2500 \ud83d\udcc2 global\n    |   \u2514\u2500\u2500 \ud83d\udcc2 base-identities\n    |    \u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc4 account.tf\n    |    \u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc4 config.tf\n    |    \u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc4 locals.tf\n    |    \u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc4 policies.tf\n    |    \u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc4 roles.tf\n    |    \u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc4 service_linked_roles.tf\n    |    \u00a0\u00a0 \u2514\u2500\u2500 \ud83d\udcc4 variables.tf\n    \u2514\u2500\u2500 \ud83d\udcc2 us-east-1\n        \u251c\u2500\u2500 \ud83d\udcc2 base-network\n        \u2502\u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc4 account.tf\n        \u2502\u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc4 config.tf\n        \u2502\u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc4 locals.tf\n        \u2502\u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc4 network.tf\n        \u2502\u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc4 network_vpc_flow_logs.tf\n        \u2502\u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc4 outputs.tf\n        \u2502\u00a0\u00a0 \u2514\u2500\u2500 \ud83d\udcc4 variables.tf\n        \u251c\u2500\u2500 \ud83d\udcc2 base-tf-backend\n        \u2502\u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc4 config.tf\n        \u2502\u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc4 locals.tf\n        \u2502\u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc4 main.tf\n        \u2502\u00a0\u00a0 \u2514\u2500\u2500 \ud83d\udcc4 variables.tf\n        \u2514\u2500\u2500 \ud83d\udcc2 security-base\n            \u251c\u2500\u2500 \ud83d\udcc4 account.tf\n            \u251c\u2500\u2500 \ud83d\udcc4 config.tf\n            \u2514\u2500\u2500 \ud83d\udcc4 variables.tf\n</code>\n\n<p>As you can see, it is a structure comprised of directories for each account containing all the definitions for each of the accounts respective layers.</p>\n<p>The layers themselves are also grouped based on the region in which they are deployed. The regions are configured through the <code>project.yaml</code> file. In the case of the Leverage landing zone, most layers are deployed in the primary region, so you can see the definition of these layers in a <code>us-east-1</code> directory, as per the example configuration.</p>\n<p>Some layers are not bound to a region because their definition is mainly comprised of resources for services that are global in nature, like IAM or Organizations. These kind of layers are kept in a <code>global</code> directory.</p>"},{"location":"getting-started/leverage-project-setup/#next-steps","title":"Next steps","text":"<p>You have now created the definition of all the infrastructure for your project and configured the credentials need to deploy such infrastructure in the AWS environment.</p>\n<p>Next, you will orchestrate the first and main account of the project, the management account.</p>"},{"location":"getting-started/local-setup/","title":"Install Leverage CLI","text":"<p>Leverage-based projects are better managed via the Leverage CLI which is a companion tool that simplifies your daily interactions with Leverage. This page will guide you through the installation steps.</p>"},{"location":"getting-started/local-setup/#prerequisites","title":"Prerequisites","text":"<p>In order to install the CLI you should have the following installed in your system:</p> <ul> <li> Git</li> <li> Python 3 <code>version 3.8 and up</code></li> <li> Docker</li> </ul>"},{"location":"getting-started/local-setup/#install-leverage-cli_1","title":"Install Leverage CLI","text":"<p>Leverage CLI is distributed as a python package that you can install it via <code>pip</code> as follows: <pre><code>pip install leverage\n</code></pre></p> <p>For further details on installing Leverage CLI:  Install Leverage CLI</p>"},{"location":"getting-started/local-setup/#verify-your-leverage-cli-installation","title":"Verify your Leverage CLI installation","text":"<p>Verify that your Leverage CLI installation was successful by running the following command: <pre><code>$ leverage --version\nleverage, version 1.9.2\n</code></pre></p> <p>It is generally recommended to install the latest stable version of the CLI</p>"},{"location":"getting-started/local-setup/#enable-tab-completion","title":"Enable tab completion","text":"<p>If you use Bash, Zsh or Fish, you can enable shell completion for Leverage commands.</p> BashZshFish <p>Add to <code>~/.bashrc</code>: <pre><code>eval \"$(_LEVERAGE_COMPLETE=bash_source leverage)\"\n</code></pre></p> <p>Add to <code>~/.zshrc</code>: <pre><code>eval \"$(_LEVERAGE_COMPLETE=zsh_source leverage)\"\n</code></pre></p> <p>Add to <code>~/.config/fish/completions/leverage.fish</code>: <pre><code>eval (env _LEVERAGE_COMPLETE=fish_source leverage)\n</code></pre></p> <p>Now you need to restart your shell.</p>"},{"location":"getting-started/local-setup/#next-steps","title":"Next steps","text":"<p>Now you have your system completely configured to work on a Leverage project.</p> <p>Next, you will setup and create your Leverage project.</p>"},{"location":"getting-started/management-account/","title":"Configure the Management account","text":"<p>Finally we reach the point in which you'll get to actually create the infrastructure in our AWS environment.</p> <p>Some accounts and layers rely on other accounts or layers to be deployed first, which creates dependencies between them and establishes an order in which all layers should be deployed. We will go through these dependencies in order.</p> <p>The management account is used to configure and access all the accounts in the AWS Organization. Consolidated Billing and Cost Management are also enforced though this account.</p> <p>Costs associated with this solution</p> <p>By default this AWS Reference Architecture configuration should not incur in any costs.</p>"},{"location":"getting-started/management-account/#deploy-the-management-accounts-layers","title":"Deploy the Management account's layers","text":"<p>To begin, place yourself in the <code>management</code> account directory. <pre><code>cd management\n</code></pre></p>"},{"location":"getting-started/management-account/#terraform-backend-layer","title":"Terraform backend layer","text":"<p>Move into the <code>us-east-1/base-tf-backend</code> directory and run: <pre><code>leverage terraform init --skip-validation\nleverage terraform apply\n</code></pre></p> <p>All <code>apply</code> commands will prompt for confirmation, answer <code>yes</code> when this happens.</p> <p>More information on <code>terraform init</code> and <code>terraform apply</code></p> <p>Now, the infrastructure for the Terraform state management is created. The next step is to push the local <code>.tfstate</code> to the bucket. To do this, uncomment the <code>backend</code> section for the <code>terraform</code> configuration in <code>management/base-tf-backend/config.tf</code></p> <pre><code>  backend \"s3\" {\n    key = \"management/tf-backend/terraform.tfstate\"\n  }\n</code></pre> <p>And run once more: <pre><code>leverage terraform init\n</code></pre></p> <p>When prompted, answer <code>yes</code>. Now you can safely remove the <code>terraform.tfstate</code> and <code>terraform.tfstate.backup</code> files created during the <code>apply</code> step.</p> <p>Terraform backend</p> <p>More information regarding what is the Terraform backend and Terraform state management:</p> <ul> <li>Terraform backend</li> <li>How to manage Terraform state</li> </ul>"},{"location":"getting-started/management-account/#organizations-layer","title":"Organizations layer","text":"<p>Next, in the same fashion as in the previous layer, move into the <code>global/organizations</code> directory and run: <pre><code>leverage terraform init\nleverage terraform apply\n</code></pre></p> <p>The AWS account that you created manually is the <code>management</code> account itself, so to prevent Terraform from trying to create it and error out, this account definition is commented by default in the code. Now you need to make the Terraform state aware of the link between the two. To do that, uncomment the <code>management</code> organizations account resource in <code>accounts.tf</code></p> <pre><code>resource \"aws_organizations_account\" \"management\" {\n  name  = \"${var.project_long}-management\"\n  email = local.management_account.email\n}\n</code></pre> <p>Grab the management account id that previously was automatically filled in for us in the <code>project.yaml</code> file</p> <pre><code>...\norganization:\n  accounts:\n    - name: management\n      email: myexample-aws@example.com\n      id: '000123456789'\n...\n</code></pre> <p>And run: <pre><code>leverage terraform import aws_organizations_account.management 000123456789\n</code></pre></p> <p>More information on <code>terraform import</code></p> <p>Getting errors with zsh?</p> <p>Zsh users may need to prepend <code>noglob</code> to the import command for it to be recognized correctly, as an alternative, square brackets can be escaped as <code>\\[\\]</code></p>"},{"location":"getting-started/management-account/#security-layer","title":"Security layer","text":"<p>Change directory to <code>us-east-1/security-base</code> and run this: <pre><code>leverage terraform init\nleverage terraform apply\n</code></pre></p>"},{"location":"getting-started/management-account/#update-the-bootstrap-credentials","title":"Update the bootstrap credentials","text":"<p>Now that the <code>management</code> account has been deployed, and more specifically, all Organizations accounts have been created (in the organizations layer) you need to update the credentials for the bootstrap process before proceeding to deploy any of the remaining accounts.</p> <p>This will fetch the organizations structure from the AWS environment and create individual profiles associated with each account for the AWS CLI to use. So, run: <pre><code>$ leverage credentials configure --type BOOTSTRAP --skip-access-keys-setup\n[09:08:44.762] INFO     Loading configuration file.\n[09:08:44.785]     Loading project environment configuration file.\n[09:08:44.791]     Loading Terraform common configuration.\n[09:08:53.247]     Configuring assumable roles.\n[09:08:53.248]     Fetching organization accounts.\n[09:08:55.193]     Backing up account profiles file.\n[09:08:55.761]             Configuring profile me-management-oaar\n[09:08:59.977]             Configuring profile me-security-oaar\n[09:09:04.081]             Configuring profile me-shared-oaar\n[09:09:08.305]     Account profiles configured in: /home/user/.aws/me/config\n[09:09:08.307] INFO     Updating project's Terraform common configuration.\n</code></pre></p> <p>More information on <code>credentials configure</code></p>"},{"location":"getting-started/management-account/#sso-layer","title":"SSO layer","text":"<p>Before working on the SSO layer you have to navigate to the AWS IAM Identity Center page, set the region to the primary region you've chosen and enable Single Sign-On (SSO) by clicking on the <code>Enable</code> button.</p> <p>Now back to the terminal. The SSO layer is deployed in two steps. First, switch to the <code>global/sso</code> directory and run the following: <pre><code>leverage terraform init\nleverage terraform apply\n</code></pre></p> <p>Secondly, open the <code>account_assignments.tf</code> file and uncomment the entire section that starts with this line: <pre><code># module \"account_assignments\" {\n#   source = \"github.com/binbashar/terraform-aws-sso.git//modules/account-assignments?ref=0.7.1\"\n\n[REDACTED]\n\n#   ]\n# }\n</code></pre></p> <p>After that, run these commands: <pre><code>leverage terraform init\nleverage terraform apply\n</code></pre></p>"},{"location":"getting-started/management-account/#next-steps","title":"Next steps","text":"<p>You have successfully orchestrated the <code>management</code> account for your project and configured the credentials for the next steps.</p> <p>Now, let's enable SSO for the rest of the process.</p>"},{"location":"getting-started/post-deployment/","title":"Post-deployment steps","text":"<p>At this point the landing zone should be ready.</p> <p>The bootstrap user can now be deleted.</p>"},{"location":"getting-started/post-deployment/#delete-the-bootstrap-user","title":"Delete the bootstrap user","text":"<ul> <li>Log into your <code>sso_start_url</code> address with your SSO user</li> <li>Select the <code>management</code> account and log into the <code>Management console</code></li> <li>Go to IAM</li> <li>Delete the user <code>mgmt-org-admin</code></li> </ul>"},{"location":"getting-started/post-deployment/#adding-sso-users-and-groups","title":"Adding SSO users and groups","text":"<p>To add users or groups, please see SSO Managing Users document.</p>"},{"location":"getting-started/post-deployment/#next-steps","title":"Next steps","text":"<p>Now you not only have a fully functional landing zone configuration deployed, but also are able to interact with it using your own AWS SSO credentials.</p> <p>For more detailed information on the binbash Leverage Landing Zone, visit the links below.</p> <ul> <li> How it works</li> <li> User guide</li> </ul>"},{"location":"getting-started/security-and-shared-accounts/","title":"Configure the Security and Shared accounts","text":"<p>You should by now be more familiar with the steps required to create and configure the Management account. Now you need to do pretty much the same with two more accounts: Security and Shared. Follow the sections in this page to get started!</p> <p>What are these accounts used for?</p> <p>The Security account is intended for operating security services (e.g. GuardDuty, AWS Security Hub, AWS Audit Manager, Amazon Detective, Amazon Inspector, and AWS Config), monitoring AWS accounts, and automating security alerting and response.</p> <p>The Shared Services account supports the services that multiple applications and teams use to deliver their outcomes. Some examples include VPN servers, monitoring systems, and centralized logs management services.</p>"},{"location":"getting-started/security-and-shared-accounts/#deploy-the-security-accounts-layers","title":"Deploy the Security account's layers","text":"<p>The next account to orchestrate is the security account.</p> <p>This account is intended for centralized user management via a IAM roles based cross organization authentication approach. This means that most of the users for your organization will be defined in this account and those users will access the different accounts through this one.</p> <p>First, go to the <code>security</code> directory. <pre><code>cd security\n</code></pre></p>"},{"location":"getting-started/security-and-shared-accounts/#set-profile","title":"Set profile","text":"<p>Since we are using SSO, check in <code>security/config/backend.tfvars</code> file the <code>profile</code> is set to:</p> <pre><code>profile = \"me-security-devops\"\n</code></pre> <p>If it is not, please modify it. Note we are using a sample short project name <code>me</code>, use the one you have set.</p>"},{"location":"getting-started/security-and-shared-accounts/#terraform-backend-layer","title":"Terraform backend layer","text":"<p>Move into the <code>us-east-1/base-tf-backend</code> directory and run: <pre><code>leverage terraform init --skip-validation\nleverage terraform apply\n</code></pre></p> <p>More information on <code>terraform init</code> and <code>terraform apply</code></p> <p>Now, to push the local <code>.tfstate</code> to the bucket, uncomment the <code>backend</code> section for the <code>terraform</code> configuration in <code>security/base-tf-backend/config.tf</code> <pre><code>  backend \"s3\" {\n    key = \"security/tf-backend/terraform.tfstate\"\n  }\n</code></pre></p> <p>And run again: <pre><code>leverage terraform init\n</code></pre></p> <p>When prompted, answer <code>yes</code>.</p> <p>Now you can safely remove the <code>terraform.tfstate</code> and <code>terraform.tfstate.backup</code> files created during the <code>apply</code> step.</p>"},{"location":"getting-started/security-and-shared-accounts/#security-layer","title":"Security layer","text":"<p>The last layer for the <code>security</code> account is the security layer. Move into the <code>us-east-1/security-base</code> directory and run: <pre><code>leverage terraform init\nleverage terraform apply\n</code></pre></p>"},{"location":"getting-started/security-and-shared-accounts/#deploy-the-shared-accounts-layers","title":"Deploy the Shared account's layers","text":"<p>The last account in this deployment is the <code>shared</code> account.</p> <p>Again, this account is intended for managing the infrastructure of shared services and resources such as directory services, DNS, VPN, monitoring tools or centralized logging solutions.</p> <p>Place yourself in the <code>shared</code> directory. <pre><code>cd shared\n</code></pre></p>"},{"location":"getting-started/security-and-shared-accounts/#set-profile_1","title":"Set profile","text":"<p>Since we are using SSO, check in <code>shared/config/backend.tfvars</code> file the <code>profile</code> is set to:</p> <pre><code>profile = \"me-shared-devops\"\n</code></pre> <p>If it is not, please modify it. Note we are using a sample short project name <code>me</code>, use the one you have set.</p>"},{"location":"getting-started/security-and-shared-accounts/#terraform-backend-layer_1","title":"Terraform backend layer","text":"<p>Move into the <code>us-east-1/base-tf-backend</code> directory and run: <pre><code>leverage terraform init --skip-validation\nleverage terraform apply\n</code></pre></p> <p>More information on <code>terraform init</code> and <code>terraform apply</code></p> <p>Now, to push the local <code>.tfstate</code> to the bucket, uncomment the <code>backend</code> section for the <code>terraform</code> configuration in <code>shared/base-tf-backend/config.tf</code> <pre><code>  backend \"s3\" {\n    key = \"shared/tf-backend/terraform.tfstate\"\n  }\n</code></pre></p> <p>And run a second time: <pre><code>leverage terraform init\n</code></pre></p> <p>When prompted, answer <code>yes</code>.</p> <p>Now you can safely remove the <code>terraform.tfstate</code> and <code>terraform.tfstate.backup</code> files created during the <code>apply</code> step.</p>"},{"location":"getting-started/security-and-shared-accounts/#security-layer_1","title":"Security layer","text":"<p>Next, move into the <code>us-east-1/security-base</code> directory: <pre><code>leverage terraform init\nleverage terraform apply\n</code></pre></p>"},{"location":"getting-started/security-and-shared-accounts/#network-layer","title":"Network layer","text":"<p>The last layer should be the network layer, so switch to that <code>us-east-1/base-network</code> and run: <pre><code>leverage terraform init\nleverage terraform apply\n</code></pre></p>"},{"location":"getting-started/security-and-shared-accounts/#next-steps","title":"Next steps","text":"<p>You have now a fully deployed landing zone configuration for the Leverage Reference Architecture for AWS, with its three accounts management, security and shared ready to be used.</p> <p>Next, you are going to tackle de last steps.</p>"},{"location":"guide/","title":"User guide","text":""},{"location":"guide/#user-guide","title":"User Guide","text":""},{"location":"guide/#overview","title":"Overview","text":"<p>The pages in this section explore, with great detail, the architecture of the components that make up Leverage.</p> <ul> <li> Reference Architectures<ul> <li> Reference Architecture for AWS</li> <li> Reference Architecture for EKS</li> <li> Reference Architecture for Ansible</li> </ul> </li> <li> Infrastructure-as-Code Library</li> <li> Leverage CLI</li> </ul> <p>But don't feel constrained to the links above, feel free to use the left menu to explore more on your own.</p>"},{"location":"guide/architecture/configuration/","title":"Configuration","text":""},{"location":"guide/architecture/configuration/#configuration-files","title":"Configuration Files","text":"<p>Config files can be found under each <code>config</code> folders</p> <ul> <li> Global config file <code>/config/common.tfvars</code>  contains global context TF variables that we inject to TF commands which are used by all sub-directories such as  <code>leverage terraform plan</code> or <code>leverage terraform apply</code> and which cannot be stored in <code>backend.tfvars</code> due to TF.</li> <li> Account config files <ul> <li><code>backend.tfvars</code>  contains TF variables that are mainly used to configure TF backend but since  <code>profile</code> and <code>region</code> are defined there, we also use them to inject those values into other TF commands.</li> <li><code>account.tfvars</code>  contains TF variables that are specific to an AWS account.</li> </ul> </li> <li> Global <code>common-variables.tf</code> file <code>/config/common-variables.tfvars</code> contains global context TF variables that we symlink to all terraform layers code e.g. shared/us-east-1/tools-vpn-server/common-variables.tf.</li> <li> <code>build.env</code> file<ul> <li>By utilizing the <code>build.env</code> capability,   you can easily change some default behaviors of the CLI. Read more in its dedicated   \"Override defaults via <code>build.env</code> file\" section.</li> </ul> </li> </ul>"},{"location":"guide/architecture/configuration/#setting-credentials-for-terraform-via-aws-profiles","title":"Setting credentials for Terraform via AWS profiles","text":"<ul> <li>File <code>backend.tfvars</code> will inject the profile name that TF will use to make changes on AWS.</li> <li>Such profile is usually one that relies on another profile to assume a role to get access to each corresponding account.</li> <li>Please read the credentials section to understand the alternatives supported by Leverage to authenticate with AWS.</li> <li>Read the following page leverage doc to understand how to set up a profile to assume  a role</li> </ul>"},{"location":"guide/architecture/dir-structure/","title":"Project Structure","text":""},{"location":"guide/architecture/dir-structure/#filesfolders-organization","title":"Files/Folders Organization","text":"<p>The following block provides a brief explanation of the chosen files/folders layout, under every account (<code>management</code>,  <code>shared</code>, <code>security</code>, etc) folder you will see a service layer structure similar to the following:</p> MyExample project file structure <pre><code>    ...\n    \u251c\u2500\u2500 \ud83d\udcc2 apps-devstg\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc2 config\n    |   \u2502\u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc4 account.tfvars\n    |   \u2502\u00a0\u00a0 \u2514\u2500\u2500 \ud83d\udcc4 backend.tfvars\n    |   \u251c\u2500\u2500 \ud83d\udcc2 global\n    |   \u2502\u00a0\u00a0 \u2514\u2500\u2500 \ud83d\udcc2 base-identities\n    |   \u251c\u2500\u2500 \ud83d\udcc2 us-east-1\n    |   \u2502\u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc2 backups\n    |   \u2502\u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc2 base-certificates\n    |   \u2502\u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc2 base-network\n    |   \u2502\u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc2 base-tf-backend\n    |   \u2502\u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc2 cdn-s3-frontend\n    |   \u2502\u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc2 databases-aurora\n    |   \u2502\u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc2 databases-mysql\n    |   \u2502\u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc2 databases-pgsql\n    |   \u2502\u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc2 k8s-eks-demoapps\n    |   \u2502\u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc2 notifications\n    |   \u2502\u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc2 security-audit\n    |   \u2502\u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc2 security-base\n    |   \u2502\u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc2 security-certs\n    |   \u2502\u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc2 security-firewall\n    |   \u2502\u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc2 storage\n    |   \u2502\u00a0\u00a0 \u2514\u2500\u2500 \ud83d\udcc2 tools-cloud-nuke\n    |   \u2514\u2500\u2500 \ud83d\udcc2 us-east-2\n    |    \u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc2 k8s-eks\n    |    \u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc2 security-compliance\n    |    \u00a0\u00a0 \u2514\u2500\u2500 \ud83d\udcc2 security-keys\n    \u251c\u2500\u2500 \ud83d\udcc2 apps-prd\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc2 config\n    |   \u2502\u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc4 account.tfvars\n    |   \u2502\u00a0\u00a0 \u2514\u2500\u2500 \ud83d\udcc4 backend.tfvars\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc2 global\n    |   \u2502\u00a0\u00a0 \u2514\u2500\u2500 \ud83d\udcc2 base-identities\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 \ud83d\udcc2 us-east-1\n    |    \u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc2 backups\n    |    \u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc2 base-network\n    |    \u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc2 base-tf-backend\n    |    \u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc2 cdn-s3-frontend\n    |    \u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc2 k8s-eks\n    |    \u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc2 notifications\n    |    \u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc2 security-audit\n    |    \u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc2 security-base\n    |    \u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc2 security-certs\n    |    \u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc2 security-compliance\n    |    \u00a0\u00a0 \u2514\u2500\u2500 \ud83d\udcc2 security-keys\n    \u251c\u2500\u2500 \ud83d\udcc4 build.env\n    \u251c\u2500\u2500 \ud83d\udcc4 build.py\n    \u251c\u2500\u2500 \ud83d\udcc2 config\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 \ud83d\udcc4 common.tfvars\n    \u251c\u2500\u2500 \ud83d\udcc2 management\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc2 config\n    |   \u2502\u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc4 account.tfvars\n    |   \u2502\u00a0\u00a0 \u2514\u2500\u2500 \ud83d\udcc4 backend.tfvars\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc2 global\n    |   \u2502\u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc2 base-identities\n    |   \u2502\u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc2 cost-mgmt\n    |   \u2502\u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc2 organizations\n    |   \u2502\u00a0\u00a0 \u2514\u2500\u2500 \ud83d\udcc2 sso\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc2 us-east-1\n    |   \u2502\u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc2 backups\n    |   \u2502\u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc2 base-tf-backend\n    |   \u2502\u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc2 notifications\n    |   \u2502\u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc2 security-audit\n    |   \u2502\u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc2 security-base\n    |   \u2502\u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc2 security-compliance\n    |   \u2502\u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc2 security-keys\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 \ud83d\udcc2 us-east-2\n    |    \u00a0\u00a0 \u2514\u2500\u2500 \ud83d\udcc2 security-monitoring\n    \u251c\u2500\u2500 \ud83d\udcc2 network\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc2 config\n    |   \u2502\u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc4 account.tfvars\n    |   \u2502\u00a0\u00a0 \u2514\u2500\u2500 \ud83d\udcc4 backend.tfvars\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc2 global\n    |   \u2502\u00a0\u00a0 \u2514\u2500\u2500 \ud83d\udcc2 base-identities\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc2 us-east-1\n    |   \u2502\u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc2 base-network\n    |   \u2502\u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc2 base-tf-backend\n    |   \u2502\u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc2 network-firewall\n    |   \u2502\u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc2 notifications\n    |   \u2502\u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc2 security-audit\n    |   \u2502\u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc2 security-base\n    |   \u2502\u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc2 security-compliance\n    |   \u2502\u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc2 security-keys\n    |   \u2502\u00a0\u00a0 \u2514\u2500\u2500 \ud83d\udcc2 transit-gateway\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 \ud83d\udcc2 us-east-2\n    |    \u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc2 base-network\n    |    \u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc2 network-firewall\n    |    \u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc2 security-compliance\n    |    \u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc2 security-keys\n    |    \u00a0\u00a0 \u2514\u2500\u2500 \ud83d\udcc2 transit-gateway\n    \u251c\u2500\u2500 \ud83d\udcc2 security\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc2 config\n    |   \u2502\u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc4 account.tfvars\n    |   \u2502\u00a0\u00a0 \u2514\u2500\u2500 \ud83d\udcc4 backend.tfvars\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc2 global\n    |   \u2502\u00a0\u00a0 \u2514\u2500\u2500 \ud83d\udcc2 base-identities\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc2 us-east-1\n    |   \u2502\u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc2 base-tf-backend\n    |   \u2502\u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc2 firewall-manager\n    |   \u2502\u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc2 notifications\n    |   \u2502\u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc2 security-audit\n    |   \u2502\u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc2 security-base\n    |   \u2502\u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc2 security-compliance\n    |   \u2502\u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc2 security-keys\n    |   \u2502\u00a0\u00a0 \u2514\u2500\u2500 \ud83d\udcc2 security-monitoring\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 \ud83d\udcc2 us-east-2\n    |    \u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc2 security-audit\n    |    \u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc2 security-compliance\n    |    \u00a0\u00a0 \u2514\u2500\u2500 \ud83d\udcc2 security-monitoring\n    \u2514\u2500\u2500 \ud83d\udcc2 shared\n    \u251c\u2500\u2500 \ud83d\udcc2 config\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 \ud83d\udcc4 account.tfvars\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 \ud83d\udcc4 backend.tfvars\n    \u251c\u2500\u2500 \ud83d\udcc2 global\n    |   \u251c\u2500\u2500 \ud83d\udcc2 base-dns\n    |   \u2514\u2500\u2500 \ud83d\udcc2 base-identities\n    \u251c\u2500\u2500 \ud83d\udcc2 us-east-1\n    |   \u251c\u2500\u2500 \ud83d\udcc2 backups\n    |   \u251c\u2500\u2500 \ud83d\udcc2 base-network\n    |   \u251c\u2500\u2500 \ud83d\udcc2 base-tf-backend\n    |   \u251c\u2500\u2500 \ud83d\udcc2 container-registry\n    |   \u251c\u2500\u2500 \ud83d\udcc2 ec2-fleet\n    |   \u251c\u2500\u2500 \ud83d\udcc2 k8s-eks\n    |   \u251c\u2500\u2500 \ud83d\udcc2 k8s-eks-demoapps\n    |   \u251c\u2500\u2500 \ud83d\udcc2 k8s-eks-prd\n    |   \u251c\u2500\u2500 \ud83d\udcc2 notifications\n    |   \u251c\u2500\u2500 \ud83d\udcc2 security-audit\n    |   \u251c\u2500\u2500 \ud83d\udcc2 security-base\n    |   \u251c\u2500\u2500 \ud83d\udcc2 security-compliance\n    |   \u251c\u2500\u2500 \ud83d\udcc2 storage\n    |   \u251c\u2500\u2500 \ud83d\udcc2 tools-cloud-scheduler-stop-start\n    |   \u251c\u2500\u2500 \ud83d\udcc2 tools-eskibana\n    |   \u251c\u2500\u2500 \ud83d\udcc2 tools-github-selfhosted-runners\n    |   \u251c\u2500\u2500 \ud83d\udcc2 tools-jenkins\n    |   \u251c\u2500\u2500 \ud83d\udcc2 tools-managedeskibana\n    |   \u251c\u2500\u2500 \ud83d\udcc2 tools-prometheus\n    |   \u251c\u2500\u2500 \ud83d\udcc2 tools-vault\n    |   \u251c\u2500\u2500 \ud83d\udcc2 tools-vpn-server\n    |   \u2514\u2500\u2500 \ud83d\udcc2 tools-webhooks\n    \u00a0\u00a0 \u2514\u2500\u2500 \ud83d\udcc2 us-east-2\n    \u251c\u2500\u2500 \ud83d\udcc2 base-network\n    \u251c\u2500\u2500 \ud83d\udcc2 container-registry\n    \u251c\u2500\u2500 \ud83d\udcc2 security-compliance\n    \u251c\u2500\u2500 \ud83d\udcc2 security-keys\n    \u251c\u2500\u2500 \ud83d\udcc2 tools-eskibana\n    \u2514\u2500\u2500 \ud83d\udcc2 tools-prometheus\n</code></pre> <p>Configuration files are organized by environments (e.g. dev, stg, prd), and service type, which we call layers (identities, organizations, storage, etc) to keep any changes made to them separate. Within each of those layers folders you should find the Terraform files that are used to define all the  resources that belong to such account environment and specific layer.</p> <p>Project file structure </p> <p>An extended project file structure could be found  here While some other basic concepts and naming conventions in the context of Leverage like \"project\" and \"layer\"  here</p> <p></p> Figure: AWS Organization multi-account architecture diagram. (Source: binbash Leverage, \"Leverage Reference Architecture components\", binbash Leverage Doc, accessed August 4th 2021).  <p>NOTE: As a convention folders with the <code>--</code> suffix reflect that the resources are not currently created in AWS, basically they've been destroyed or not yet exist. </p> <p>Such layer separation is meant to avoid situations in which a single folder contains a lot of resources.  That is important to avoid because at some point, running <code>leverage terraform plan / apply</code> starts taking  too long and that becomes a problem.</p> <p>This organization also provides a layout that is easier to navigate and discover.  You simply start with the accounts at the top level and then you get to explore the resource categories within  each account.</p>"},{"location":"guide/architecture/features/","title":"High Level Design","text":""},{"location":"guide/architecture/features/#features","title":"Features","text":"Sl.       Features Actors Remarks 1Assurance provider onboardingAssurance Provider 2OSS producer and consumer onboardingConsumer  3Marketplace operator onboardingMarketplace Operator 4Marketplace subscriptionAssurance Provider, Consumer 5Add / modify / delete OSS projects into the projects of interest for assurance providerAssurance ProviderWhile adding or modifying a OSS asset, the OASP should make sure that the attested assessment reports are made available 6Add / modify / delete OSS models into the models of interest for assurance providerAssurance ProviderWhile adding or modifying a OSS asset, the OASP should make sure that the attested assessment reports are made available 7Search for an OSS projectConsumer 8Search for an OSS modelConsumer 9Place an order for a particular assurance service on an existing OSS artifactConsumerThe assessment artifcats are made available at this time.     Where do we bring in the payment? 10Place a request for the assurance service on a new OSS artifactConsumerShould we split this into OSS model and projects? 11Risk Assessment report 12Bug bounty program 13Remediate a particular bug  14Bid for the new OSS project or model onboarding request Assurance Provider"},{"location":"guide/architecture/features/#ossverse-user-interface-views","title":"OSSVerse User Interface Views","text":""},{"location":"guide/architecture/features/#public-view","title":"Public View","text":"<ol> <li> <p>OSSVerse Homepage (ossverse.com)</p> <ul> <li>Logo placeholder</li> <li>Top menu navigation</li> <li>Menus : Platform, Solutions, Resources, Company, Sign In, Get Started, Book a demo</li> <li>Marketing banner placeholder. Also has buttons for Get Started and Explore Marketplace</li> <li>Featured Offerings section</li> <li>Featured Assurance Provider section with buttons to navigate to each of their offerings</li> <li>Bottom banner with links to website navigation</li> <li>Copyright text</li> </ul> </li> <li> <p>Explore marketplace</p> <ul> <li>Navigate to the search page from the home page. Shows the complete list of  OSS Software / Model list page with search and filter</li> <li>Each item to be represented as tiles. Each tile should have the OSS artifact name, artifact type indicator (ML model / Project), first few lines of the description, OSSVerse recommended OASP name providing this offering. The user click on a tile will redirects to Login or Sign Up as a business user</li> </ul> </li> </ol>"},{"location":"guide/architecture/features/#producer-business","title":"Producer / Business","text":"<ol> <li>OSS artifact details page <ul> <li>Opens up post login and when the user click on an OSS Project / Model tile from the explore marketplace view. </li> <li>The details page should contain the below key elements.</li> <li>Name of the artifact</li> <li>Detailed description</li> <li>Price of assessment service (This includes 1 OASP doing assessment and 2 OASPs doing a validation). The business user is going to get an assessment report which is attested from OASP1 and validated by 2 other OASPs as end delivery</li> <li>Default selection of marketplace recommend OASP for assessment and 2 OASPs for validation. (User will have the option to change the OASPs. The pricing will change accordingly)</li> <li>Button to place an order. Once order is placed, the page redirects to the order tracking screen.</li> </ul> </li> <li>Order details and tracking page <ul> <li>User intuitive representation of the progress of a single order from start to delivery. </li> <li>Show the transaction id, OASPs delivering the service, order details, payment information, billing information, expected time of delivery</li> <li>Provision to edit billing information</li> <li>Provision to cancel the order if the OASP is yet to accept it</li> <li>Link to download the deliverables. Attested and certified assessment report can be downloaded if the delivery is complete.</li> <li>The same page can be used in the OASP view to see the order details before accepting or rejecting it. </li> </ul> </li> <li>My orders<ul> <li>Shows the complete list of orders placed by this organization. </li> <li>On click of an item, page redirects to \u201cOrder details and tracking page\u201d.</li> </ul> </li> </ol>"},{"location":"guide/architecture/features/#open-source-assurance-provider-view","title":"Open Source Assurance Provider View","text":"<ol> <li>Dashboard<ul> <li>Gives a holistic view of the assurance provider business. </li> <li>Count of assigned orders for assessment. It\u2019s a hyperlink to the pending assessment order list.</li> <li>Count of assigned orders for validation. It\u2019s a hyperlink to the pending validation order list.</li> <li>Count of open challenges OASP can bid for. It\u2019s a hyperlink to the open challenges page.</li> <li>Statistics section about the overall business, revenue etc</li> <li>Count of Open Source Projects this OASP is offering services. It\u2019s a hyperlink to the OSS projects list page</li> <li>Count of Open Source Models this OASP is offering services. It\u2019s a hyperlink to the OSS models list page</li> </ul> </li> <li>Assessment orders page<ul> <li>Lists all assessment orders assigned to this OASP. Both OSS projects and models assessments are listed here. This should have search and filter feature.</li> <li>The list can be represented as a table</li> <li>On click of a row redirects the page to \u201cOrder details and tracking page\u201d that is similar to the \u201cBusiness/Producer\u201d user view. </li> </ul> </li> <li>Risk Assessment Order details and tracking<ul> <li>\u201cOrder details and tracking page\u201d that is similar to the \u201cBusiness/Producer\u201d user view</li> <li>Accept and reject button. In case of rejection, there will be a reject reason text box appears before submit.</li> <li>Provision to mark the order as complete. User should be able to upload the deliverables at this stage.</li> </ul> </li> <li>Validation orders page<ul> <li>Lists all validation orders assigned to this OASP</li> <li>The list can be represented as a table</li> <li>On click of a row redirects the page to \u201cOrder details and tracking page\u201d that is similar to the \u201cBusiness/Producer\u201d user view. Only addition is the Accept and reject button. In case of rejection, there will be a reject reason text box appears before submit.</li> </ul> </li> <li>Open challenges page<ul> <li>Lists all the open on-demand challenges published in the marketplace</li> <li>The list can be represented as a table</li> <li>On click of a row redirects the page to \u201cChallenge details\u201d page</li> </ul> </li> <li>Challenge details page<ul> <li>Challenge details should be there. This is similar to TopCoder challenge details page.</li> <li>Provision to bid for the challenge with pricing, delivery timelines, deliverables etc</li> </ul> </li> <li>Open source projects listing page<ul> <li>Table representation of all projects this OASP supports.</li> <li>Search and filter should be there</li> <li>On click of a row redirects the page to OSS project details page.</li> <li>Button to list new OSS project to marketplace</li> </ul> </li> <li>Open source project details page<ul> <li>Project name</li> <li>Description</li> <li>GitHub URL</li> <li>Modify button click makes this page editable</li> <li>Modify offerings checkboxes</li> <li>Risk Assessment</li> <li>Third-party validation of risk assessment</li> <li>Vulnerability remediation</li> <li>TAVOSS version (TAVOSS: Trusted and Verified Open Source Software)</li> <li>Feature enhancement</li> </ul> </li> <li>List new OSS project to marketplace<ul> <li>Project name</li> <li>Description</li> <li>GitHub URL</li> <li>Checkboxes to select the services that can be offered on the model</li> <li>Risk Assessment</li> <li>Third-party validation of risk assessment</li> <li>Vulnerability remediation</li> <li>TAVOSS version (TAVOSS: Trusted and Verified Open Source Software)</li> <li>Feature enhancement</li> </ul> </li> <li>Open source models listing page<ul> <li>Table representation of all ML models this OASP supports.</li> <li>Search and filter should be there</li> <li>On click of a row redirects the page to ml model details page.</li> <li>Button to list new ML model to marketplace</li> </ul> </li> <li>ML model details page<ul> <li>Model name</li> <li>Description</li> <li>GitHub / HuggingFace URL</li> <li>Modify button click makes the page editable</li> <li>Modify offerings checkboxes</li> <li>Risk Assessment</li> <li>Third-party validation of risk assessment</li> </ul> </li> <li>List new ML model to marketplace<ul> <li>Model name</li> <li>Description</li> <li>GitHub / HuggingFace URL</li> <li>Checkboxes to select the services that can be offered on the model</li> <li>Risk Assessment</li> <li>Third-party validation of risk assessment</li> </ul> </li> </ol>"},{"location":"guide/architecture/features/#marketplace-operator","title":"Marketplace Operator","text":"<ol> <li>Dashboard<ul> <li>This is a typical business analytics dashboard</li> <li>Pending order count across OASPs</li> <li>Count of open challenges and number of bids</li> <li>Completed order count during a time window</li> <li>Overall revenue during a time window</li> <li>Count of active OASPs</li> <li>Geography wise automotive company view who are placing orders</li> </ul> </li> <li>Marketplace Configurations<ul> <li>User should be able to modify configurations for the below</li> <li>Assessment pricing and validation percentages for OASP1, OASP2 and OASP3</li> <li>Configuration to enable or disable OASP recommendations for the assessment of OSS artifacts</li> <li>Business, OASP and OSSVerse operator user management</li> </ul> </li> </ol>"},{"location":"guide/architecture/overview/","title":"AWS Reference Architecture","text":""},{"location":"guide/architecture/overview/#overview","title":"Overview","text":"<p>The AWS Reference Architecture was created on a set of opinionated definitions and conventions on:</p> <ul> <li>how to organize files/folders,</li> <li>where to store configuration files,</li> <li>how to handle credentials,</li> <li>how to set up and manage state,</li> <li>which commands and workflows to run in order to perform different tasks,</li> <li>and more.</li> </ul> <p>Key Concept</p> <p>Although the Reference Architecture for AWS was initially designed to be compatible with web, mobile and microservices application stacks, it can also accommodate other types of workloads such as machine learning, blockchain, media, and more.</p> <p>It was designed with modularity in mind. A multi-accounts approach is leveraged in order to improve security isolation and resources separation. Furthermore each account infrastructure is divided in smaller units that we call layers. Each layer contains all the required resources and definitions for a specific service or feature to function.</p> <p>Key Concept</p> <p>The design is strongly based on the AWS Well Architected Framework.</p> <p>Each individual configuration of the Reference Architecture is referred to as a project. A Leverage project is comprised of all the relevant accounts and layers.</p>"},{"location":"guide/architecture/overview/#core-strengths","title":"Core Strengths","text":"<ul> <li> Faster updates (new features and bug fixes).</li> <li> Better code quality and modules maturity (proven and tested).</li> <li> Supported by binbash, and public modules even by 1000's of top talented Open Source community      contributors.</li> <li> Increase development cost savings.</li> <li> Clients keep full rights to all commercial, modification, distribution, and private use of the code      (No Lock-In) through forks inside their own projects' repositories (open-source and commercially reusable via license MIT and Apache 2.0.</li> </ul>"},{"location":"guide/architecture/overview/#a-more-visual-example","title":"A More Visual Example","text":"<p>The following diagram shows the type of AWS multi-account setup you can achieve by using this Reference Architecture: </p> Figure: AWS Organization multi-account reference architecture diagram. (Source: binbash Leverage, \"Leverage Reference Architecture components\", binbash Leverage Doc, accessed August 4th 2021).  <p>Read more</p> <ul> <li> Don't get locked up into avoiding lock-in</li> <li> AWS Managed Services</li> </ul>"},{"location":"guide/architecture/target-architecture/","title":"OSSVerse","text":""},{"location":"guide/architecture/target-architecture/#1-business-context","title":"1. Business Context","text":"<p>OSSVerse is an open source Marketplace. It is conceptualized as an eco system project comprising of multiple platforms. It is an adaptation of ONDC and Beckn protocol for open source software service delivery . OSSVerse leverages BeSecure(BeS) for delivering open source software security assurance services . OSSVerse aims to establish an open network of OASPs for businesses that will offer trustworthy and reliable open source software assurance services. </p>"},{"location":"guide/architecture/target-architecture/#12-business-architecture","title":"1.2 Business Architecture","text":"<p>1.2.1 Marketplace Services </p> <p>1.2.1.1 Onboarding services :</p> <p>### Account Creation:</p> <p>OASP</p> <p>Creating an OSSVerse Account &amp; OASP profile for OASP     The Account creation service will register OASP with OSSVerse Registry and have APIs to update the OASP profile. An OASP profile will have informed related to payments and BAP Seller App end points (e.g instance of BAP compatible adaptation of a BeSLab )</p> <p>Business</p> <p>Creating an OSSVerse Account for a Business </p> <p>1.2.1.2 Search:      Business     a) A Business who is a consumer of Open source     Searching for OASP , open source component and open source support services like      1. Open source assessment &amp; Attestation services (Subscription based)     2. Open source remediation Services (On Demand)     3. Open source feature enhancement Services (On Demand)</p> <pre><code>b) A Business who is a Producer or Distributor of Open source\nSearching for an OASP for an identified open source component for certification (On Demand)\n</code></pre>"},{"location":"guide/architecture/target-architecture/#oasp-services","title":"OASP Services","text":"<p>1. Assurance &amp; Assessment Service: Open-source software undergoes rigorous evaluation for security, compliance, and quality, culminating in comprehensive reports and proof of attestation to ensure trustworthiness. </p> <p>1.1 Assurance Levels &amp; Services</p> <p>Based on the depth and scope of the assessment required, different assurance levels are offered, each encompassing specific checks and activities:</p> Assurance Level Description Key Emphasis/Requirement Example Checks/Activities 0 No Assurance No formal assessment - Project information gathering 1 Basic Assurance Basic automated security checks, with proof of attestation - SAST (static code analysis) 2 Standard Assurance Everything in Basic (including proof of attestation) + Dependency &amp; license compliance checks - Dependency vulnerability checks  - License compliance audit - SAST 3 Comprehensive Assurance Everything in Standard (including proof of attestation) + Dynamic and manual security review - Dynamic application security testing (if applicable)  - Expert code review (optional) - Fuzzing 4 Domain-Specific Assurance Everything in Comprehensive (including proof of attestation) + Industry-specific safety and security checks - Adherence to e.g. ISO 26262 and other domain specific standards.  - Hardware-in-the-loop (HIL) testing.  - Fuzzing and symbolic execution. <p>1.2 Open-Source Software (OSS) Assurance Service Checklist</p> <p>This checklist outlines the key steps involved in assessing the security, quality, and compliance of open-source software, especially in the automotive domain.</p> <p>1.2.1 Standard Checks</p> Assurance Check Category Subcategory (Intent) BeS Env Name Example Playbook Name Open-Source Tools SAST (Static Analysis) Security Vulnerability Scan <code>besman-code_analysis-env.sh</code> <code>besman-sast-sonarqube-playbook.sh</code>, <code>besman-sast-codeql-playbook.sh</code> SonarQube (Community Edition), PVS-Studio, CodeQL, Semgrep, Bandit, ESLint, Pylint DAST (Dynamic Analysis) Security Vulnerability Scan <code>besman-dynamic_analysis-env.sh</code> <code>besman-dast-zap-playbook.sh</code> OWASP ZAP, Arachni, Nikto, w3af, Burp Suite Dependency Analysis Dependency Vulnerability Check <code>besman-dependency_analysis-env.sh</code> <code>besman-dependency_check-playbook.sh</code> OWASP Dependency-Check, Retire.js, Synk, WhiteSource Licensing &amp; Compliance License Compliance Audit <code>besman-legal_compliance-env.sh</code> <code>besman-license_compliance-fossology-playbook.sh</code> FOSSology, LicenseFinder, ScanCode, Toolkit Code Quality Analysis Code Quality Assessment <code>besman-code_analysis-env.sh</code> <code>besman-code_quality-sonarqube-playbook.sh</code> SonarQube (Community Edition), PMD, Checkstyle, FindBugs <p>1.2.2 Automotive-Specific Checks</p> Assurance Check Category Subcategory (Intent) BeS Env Name Example Playbook Name Open-Source Tools Safety Assurance Functional Safety Assessment <code>besman-safety_critical-env.sh</code> <code>besman-safety_assurance-latte-playbook.sh</code> Frama-C, CBMC, SPIN, LATTE Security for Autonomous Driving Adversarial ML &amp; Security Assessment <code>besman-security_assessment_env.sh</code> <code>besman-autonomous_driving_security-carla_art-playbook.sh</code> CARLA Adversarial Robustness Toolbox (ART), OpenSCENARIO Real-Time Performance Real-Time Performance Analysis <code>besman-safety_critical-env.sh</code> <code>besman-real_time_performance-cyclictest-playbook.sh</code> <code>cyclictest</code> Data Privacy &amp; Security Data Privacy Assessment <code>besman-security_assessment_env.sh</code> <code>besman-data_privacy-openssl-playbook.sh</code> OpenSSL, GPG Interoperability &amp; Compatibility Protocol Conformance Testing <code>besman-network_simulation_env.sh</code> <code>besman-protocol_conformance-cantools-playbook.sh</code> Cantools, OpenXC Hardware Integration HIL Testing <code>besman-hardware_integration-env.sh</code> <code>besman-hardware_integration-renode-playbook.sh</code> Renode, QEMU Additional Checks Deep Vulnerability Scan <code>besman-symbolic_execution_fuzzing-env.sh</code> <code>besman-fuzzing-afl-playbook.sh</code> KLEE (Symbolic Execution), AFL (Fuzzing), Flawfinder, cppcheck <p>1.3 Proof of Attestation</p> Assurance Check Category BeS Env Name Example Playbook Name Open-Source Tools Attestation <code>besman-secure_artifact_signing-env.sh</code> <code>besman-artifact_signing-playbook.sh</code> Sigstore, in-toto framework (OpenSSF), The Update Framework (TUF) <p>Note:  Playbook names are provided in a generic way to emphasize their reusability across different projects. The actual playbook implementation would need to handle project-specific configurations and inputs. </p> <ol> <li> <p>Validation &amp; Verification Service: (validated &amp; verify if attestation has been done in line with the acceptable OSSVerse OASP Assessment Standard)</p> <ol> <li>Check BeS Environments (Exists/Linting)</li> <li>Check Playbooks w.rt each Check part of Assessment claimed.</li> <li>OSAR(Open source assessment/attestation Report) updated with Proof of Verfication &amp; Validation as evidence to be shared (This could be inline with an accept standard like Attestation standard like CycloneDX Attestation standard)</li> </ol> </li> <li> <p>Remediation Service:</p> </li> <li>Pentesting Service:</li> <li>Feature Addition:</li> <li>TAVOSS Version &amp; Certification Service: (Certification with or without/Distribution?/hosting?)</li> </ol> <p>Business Support Services</p>"},{"location":"guide/architecture/target-architecture/#technical-architecture","title":"Technical Architecture","text":""},{"location":"guide/architecture/target-architecture/#communication-between-beslab-ossverse","title":"Communication between BeSlab &amp; OSSVerse","text":""},{"location":"guide/architecture/target-architecture/#ossverse-as-a-bapbgopen-network-registry","title":"OSSVerse as A BAP/BG/Open Network Registry","text":""},{"location":"guide/architecture/target-architecture/#oasp-as-bpp","title":"OASP as BPP","text":"<p>Extending BeSLab as a BPP</p>"},{"location":"guide/architecture/target-architecture/#bes-establish-provenance-presentation-of-proofs","title":"BeS : Establish provenance &amp; presentation of Proofs","text":""},{"location":"guide/architecture/target-architecture/#bes-osar","title":"BeS : OSAR","text":""},{"location":"guide/ossverse-in-a-box/credentials/","title":"Credentials","text":""},{"location":"guide/ossverse-in-a-box/credentials/#overview","title":"Overview","text":"<p>Currently the following two methods are supported:</p> <ol> <li> AWS IAM: this is essentially using on-disk, permanent programmatic credentials that are tied to a given IAM User. This method can optionally support MFA which is highly recommended since using permanent credentials is discouraged, so at least with MFA you can counter-balance that. Keep reading...</li> <li> AWS IAM Identity Center (formerly known as AWS SSO): this one is more recent and it's the method recommeded by AWS since it uses roles (managed by AWS) which in turn enforce the usage of temporary credentials. Keep reading...</li> </ol>"},{"location":"guide/ossverse-in-a-box/credentials/#next-steps","title":"Next Steps","text":"<p>If you are planning to choose SSO (highly recommended), check out this section.</p> <p>If you are instead interested in using IAM + MFA, refer to this other section instead.</p>"},{"location":"guide/ossverse-in-a-box/references/","title":"References","text":"<p>The following are official AWS documentations, blog posts and whitepapers we have considered while building our Reference Solutions Architecture:</p> <ul> <li> CloudTrail for AWS Organizations</li> <li> Reserved Instances - Multi Account</li> <li> AWS Multiple Account Security Strategy</li> <li> AWS Multiple Account Billing Strategy</li> <li> AWS Secure Account Setup</li> <li> Authentication and Access Control for AWS Organizations</li> <li> AWS Regions</li> <li> VPC Peering</li> <li> Route53 DNS VPC Associations</li> <li> AWS Well Architected Framework</li> <li> AWS Tagging strategies</li> <li> Inviting an AWS Account to Join Your Organization</li> </ul>"},{"location":"guide/ossverse-in-a-box/tf-state/","title":"Terraform - S3 &amp; DynamoDB for Remote State Storage &amp; Locking","text":""},{"location":"guide/ossverse-in-a-box/tf-state/#overview","title":"Overview","text":"<p>Use this terraform configuration files to create the S3 bucket &amp; DynamoDB table needed to use Terraform Remote State Storage &amp; Locking.</p> <p>What is the Terraform Remote State?</p> <p>Read the official definition by Hashicorp.</p> <p></p> Figure: Terraform remote state store &amp; locking necessary AWS S3 bucket and DynamoDB table components. (Source: binbash Leverage,   \"Terraform Module: Terraform Backend\", Terraform modules registry, accessed December 3rd 2020)."},{"location":"guide/ossverse-in-a-box/tf-state/#prerequisites","title":"Prerequisites","text":"<p>Terraform repo structure + state backend initialization</p> <ol> <li>Ensure you have <code>Leverage CLI</code> installed in your system</li> <li>Refer to Configuration Pre-requisites to understand how to set up the   configuration files required for this layer. Where you must build your   Terraform Reference Architecture account structure</li> <li>Leveraged by the Infrastructure as Code (IaC) Library through the  terraform-aws-tfstate-backend module<ul> <li>/management/base-tf-backend</li> <li>/security/base-tf-backend</li> <li>/shared/base-tf-backend</li> <li>/network/base-tf-backend</li> <li>/apps-devstg/base-tf-backend</li> <li>/apps-prd/base-tf-backend</li> </ul> </li> </ol>"},{"location":"guide/ossverse-in-a-box/tf-state/#set-up","title":"Set up","text":"<p>Steps to initialize your tf-backend</p> <ol> <li>At the corresponding account dir,    eg: /shared/base-tf-backend then,</li> <li>Run <code>leverage terraform init --skip-validation</code></li> <li>Run <code>leverage terraform plan</code>, review the output to understand the expected changes</li> <li>Run <code>leverage terraform apply</code>, review the output once more and type <code>yes</code> if you are okay with that</li> <li> <p>This should create a <code>terraform.tfstate</code> file in this directory but we don't want to push that to the repository so    let's push the state to the backend we just created</p> <ul> <li>Open <code>config.tf</code> and uncomment the following lines: <pre><code>  # backend \"s3\" {\n  #   key = \"shared/tf-backend/terraform.tfstate\"\n  # }\n</code></pre></li> <li>Run <code>leverage terraform init</code> and type <code>yes</code> when Terraform asks if you want to import the state to the S3 backend</li> <li>Done. You can remove <code>terraform.tfstate</code> now (and also <code>terraform.tfstate.backup</code> if available)</li> </ul> </li> </ol>"},{"location":"guide/ossverse-in-a-box/tf-state/#expected-workflow-after-set-up","title":"Expected workflow after set up","text":"<p> This video is outdated! </p>"},{"location":"guide/ossverse-in-a-box/tf-state/#terraform-remote-state","title":"Terraform Remote State","text":"<p>In the <code>base-tf-backend</code> folder you should find the definition of the infrastructure that needs to be deployed before  you can get to work with anything else.</p> <p>IMPORTANT: THIS IS ONLY NEEDED IF THE BACKEND WAS NOT CREATED YET. IF THE BACKEND ALREADY EXISTS YOU JUST USE IT.</p>"},{"location":"guide/ossverse-in-a-box/workflow/","title":"Workflow","text":""},{"location":"guide/ossverse-in-a-box/workflow/#overview","title":"Overview","text":"<p>The sequence of commands that you run to operate on each layer is called the Terraform workflow. In other words, it's what you would typically run in order to create, update, or delete the resources defined in a given layer.</p>"},{"location":"guide/ossverse-in-a-box/workflow/#the-basic-workflow","title":"The basic workflow","text":"<p>Assuming that you have everything configured, the frequent commands you'll need to run are these: <pre><code># 1. Initialize\nleverage terraform init\n\n# 2. Preview any changes\nleverage terraform plan\n\n# 3. Apply any changes\nleverage terraform apply\n</code></pre></p>"},{"location":"guide/ossverse-in-a-box/workflow/#the-extended-workflow","title":"The extended workflow","text":"<p>Now, the extended workflow is annotated with more explanations and it is intended for users who haven't yet worked with Leverage on a daily basis:</p> <p>Terraform Workflow</p> <ol> <li>Make sure you understood the basic concepts:<ul> <li> Overview</li> <li> Configuration</li> <li> Directory Structure</li> <li> Remote State</li> </ul> </li> <li>Make sure you installed the Leverage CLI.</li> <li>Go to the layer (directory) you need to work with, e.g. <code>shared/global/base-identities/</code>.</li> <li>Run <code>leverage terraform init</code> -- only the first time you work on this layer, or if you upgraded modules or providers versions, or if you made changes to the Terraform remote backend configuration.</li> <li>Make any changes you need to make. For instance: modify a resource definition, add an output, add a new resource, etc.</li> <li>Run <code>leverage terraform plan</code> to preview any changes.</li> <li>Run <code>leverage terraform apply</code> to give it a final review and to apply any changes.</li> </ol> <p>Tip</p> <p>You can use the <code>--layers</code> argument to run Terraform commands on more than one layer. For more information see here</p> <p>Note</p> <p>If desired, at step #5 you could submit a PR, allowing you and the rest of the team to  understand and review what changes would be made to your AWS Cloud Architecture components before executing  <code>leverage terraform apply</code> (<code>terraform apply</code>). This brings the huge benefit of treating changes with a GitOps oriented  approach, basically as we should treat any other code &amp; infrastructure change, and integrate it with the  rest of our tools and practices like CI/CD, in</p>"},{"location":"guide/ossverse-in-a-box/workflow/#running-in-automation","title":"Running in Automation","text":"Figure: Running terraform with AWS in automation (just as reference). <p>Read More</p> <ul> <li> Running Terraform in automation</li> </ul>"},{"location":"guide/releases/releases-and-versions/","title":"Leverage Product Releases","text":"<p>Dear Leveragers, We're constantly kicking with a lot of improvements and some exciting new features</p>"},{"location":"guide/releases/releases-and-versions/#reference-architecture","title":"Reference Architecture","text":"<p> RELEASES</p> <ul> <li>Releases | Reference Architecture for AWS</li> <li>Releases | Reference Architecture for HCP Vault</li> </ul>"},{"location":"guide/releases/releases-and-versions/#leverage-cli","title":"Leverage CLI","text":"<p> RELEASES</p> <ul> <li>Releases | <code>leverage-cli</code></li> </ul>"},{"location":"guide/releases/releases-and-versions/#infrastructure-as-code-library","title":"Infrastructure as Code Library","text":"<p> RELEASES</p> <p> Releases |Terraform Leverage\u2122 Modules :</p> <ul> <li>terraform-aws-waf-owasp</li> <li>terraform-aws-cost-billing-alarm</li> <li>terraform-aws-vpc-flowlogs</li> <li>terraform-aws-cost-budget</li> <li>terraform-aws-tfstate-backend</li> <li>terraform-aws-certbot-lambda</li> <li>terraform-aws-ec2-basic-layout</li> <li>terraform-aws-natgw-notifications</li> <li>terraform-aws-guardduty-multiaccount</li> <li>terraform-aws-network-firewall</li> <li>terraform-aws-backup-notifications</li> <li>terraform-aws-rds-export-to-s3</li> </ul> <p> Releases | Terraform Community Forks Modules:</p> <ul> <li>terraform-aws-sso</li> <li>...</li> </ul> <p> Releases | Helm Leverage\u2122 Charts:</p> <ul> <li>helm-charts</li> </ul>"},{"location":"guide/releases/releases-and-versions/#documentation","title":"Documentation","text":"<p> RELEASES</p> <ul> <li>Releases | binbash Leverage\u2122 Documentation</li> </ul>"},{"location":"guide/releases/versions-compatibility-matrix/","title":"Leverage Releases &amp; Versioning","text":"<p>binbash Leverage\u2122 and its components intends to be backward compatible, but due to the complex ecosystems of tools we manage this is not always possible.</p> <p>It is always recommended using the latest version of the Leverage CLI with the latest versions of the Reference Architecture for AWS. In case that's not possible we always recommend pinning versions to favor stability and doing controlled updates component by component based on the below presented compatibility matrix table.</p>"},{"location":"guide/releases/versions-compatibility-matrix/#compatibility-matrix","title":"Compatibility Matrix","text":"<p>If you need to know which Leverage CLI versions are compatible with which Leverage Toolbox Docker Images please refer to the Release Notes. Just look for the section called \"Version Compatibility\". Bear in mind though that, at the moment, we do not include a full compatibility table there but at least you should be able to find out what's the Toolbox Image that was used for a given release.</p> <p>If you are looking for the versions of the software included in the Toolbox Docker Image then go instead to the release notes of that repo instead.</p>"},{"location":"guide/releases/versions-compatibility-matrix/#release-schedule","title":"Release Schedule","text":"<p>This project does not follow the Terraform or other release schedule. Leverage aims to provide a reliable deployment and operations experience for the binbash Leverage\u2122 Reference Architecture for AWS, and typically releases about a quarter after the corresponding Terraform release. This time allows for the Terraform project to resolve any issues introduced by the new version and ensures that we can support the latest features.</p>"},{"location":"guide/releases/versions-compatibility-matrix/#read-more","title":"Read more","text":"<p>Reference links</p> <p>Consider the following extra links as reference:</p> <ul> <li> Hashicorp Terraform releases</li> <li> Amazon EKS Kubernetes release calendar</li> <li> Amazon EKS Kubernetes versions - Amazon EKS</li> </ul>"},{"location":"guide/troubleshooting/","title":"Troubleshooting","text":""},{"location":"guide/troubleshooting/#repositories","title":"Repositories","text":"<ul> <li> General Issues</li> <li> Credential Issues</li> </ul>"},{"location":"guide/troubleshooting/credentials/","title":"Troubleshooting credentials issues","text":"<p>Make sure you read general troubleshooting page before trying out anything else.</p>"},{"location":"guide/troubleshooting/credentials/#are-you-using-iam-or-sso","title":"Are you using IAM or SSO?","text":"<p>Leverage supports two methods for getting AWS credentials: IAM and SSO. We are progressively favoring SSO over IAM, only using the latter as a fallback option.</p> <p>SSO is enabled through the common.tfvars file on this line: <pre><code>sso_enabled   = true\n</code></pre> If that is set to true, then you are using SSO, otherwise it's IAM.</p>"},{"location":"guide/troubleshooting/credentials/#why-should-i-care-whether-i-am-using-iam-or-sso","title":"Why should I care whether I am using IAM or SSO?","text":"<p>Well, because even though both methods will try to get temporary AWS credentials, each method will use a different way to do that. In fact, Leverage relies on the AWS CLI to get the credentials and each method requires completely different commands to achieve that.</p>"},{"location":"guide/troubleshooting/credentials/#do-you-have-mfa-enabled","title":"Do you have MFA enabled?","text":"<p>MFA is optionally used via the IAM method. It can be enabled/disabled in the build.env file.</p> <p>Keep in mind that MFA should only be used with the IAM method, not with SSO.</p>"},{"location":"guide/troubleshooting/credentials/#identify-which-credentials-are-failing","title":"Identify which credentials are failing","text":"<p>Since Leverage actually relies on Terraform and, since most of the definitions are AWS resources, it is likely that you are having issues with the Terraform AWS provider, in other words, you might be struggling with AWS credentials. Now, bear in mind that Leverage can also be used with other providers such as Gitlab, Github, Hashicorp Cloud Platform, or even SSH via Ansible; so the point here is to understand what credentials are not working for you in order to focus the troubleshooting on the right suspect.</p>"},{"location":"guide/troubleshooting/credentials/#determine-the-aws-profile-you-are-using","title":"Determine the AWS profile you are using","text":"<p>When you are facing AWS credentials issues it's important to understand what is the AWS profile that might be causing the issue. Enabling verbose mode should help with that. The suspect profile is likely to show right above the error line and, once you have identified that, you can skip to the next section.</p> <p>If the above doesn't make the error evident yet, perhaps you can explore the following questions:</p> <ol> <li>Is it a problem with the Terraform remote state backend? The profile used for that is typically defined in the backend.tfvars file, e.g. this one, or this other one.</li> <li>Is it a problem with another profile used by the layer? Keep in mind that layers can have multiple profile definitions in order to be able to access resources in different accounts. For instance, this is a simple provider definition that uses a single profile, but here's a more complex definition with multiple provider blocks.</li> <li>Can the problematic profile be found in the AWS config file? Or is the profile entry in the AWS config file properly defined? Read the next sections for more details on that.</li> </ol>"},{"location":"guide/troubleshooting/credentials/#check-the-profiles-in-your-aws-config-file","title":"Check the profiles in your AWS config file","text":"<p>Once you know what AWS profile is giving you headaches, you can open the AWS config file, typically under <code>~/.aws/[project_name_here]/config</code>, to look for and inspect that profile definition.</p> <p>Things to look out for:</p> <ul> <li>Is there a profile entry in that file that matches the suspect profile?</li> <li>Are there repeated profile entries?</li> <li>Does the profile entry include all necessary fields (e.g. region, role_arn, source_profile; mfa_serial if MFA is enabled)?</li> <li>Keep in mind that profiles change depending on if you are using SSO or IAM for getting credentials so please refer to the corresponding section below in this page to find specific details about your case.</li> </ul>"},{"location":"guide/troubleshooting/credentials/#configure-the-aws-cli-for-leverage","title":"Configure the AWS CLI for Leverage","text":"<p>These instructions can be used when you need to test your profiles with the AWS CLI, either to verify the profiles are properly set up or to validate the right permissions were granted.</p> <p>Since Leverage stores the AWS config and credentials file under a non-default path, when using the AWS CLI you'll need to point it to the right locations: <pre><code>export AWS_CONFIG_FILE=~/.aws/[project_name_here]/config\nexport AWS_SHARED_CREDENTIALS_FILE=~/.aws/[project_name_here]/credentials\n</code></pre></p> <p>Get shell access to the Leverage Toolbox Docker Image</p> <p>Another alternative, if you can't or don't want to install the AWS CLI on your machine, is to use the one included in the Leverage Toolbox Docker image. You can access it by running <code>leverage tf shell</code></p>"},{"location":"guide/troubleshooting/credentials/#test-the-failing-profile-with-the-aws-cli","title":"Test the failing profile with the AWS CLI","text":"<p>Once you have narrowed down your investigation to a profile what you can do is test it. For instance, let's assume that the suspect profile is <code>le-shared-devops</code>. You can run this command: <code>aws sts get-caller-identity --profile le-shared-devops</code> in order to mimic the way that AWS credentials are generated in order to be used by Terraform, so if that command succeeds then that's a good sign.</p> <p>Note: if you use the AWS CLI installed in your host machine, you will need to configure the environment variables in the section \"Configure the AWS CLI for Leverage\" below.</p> <p>AWS CLI Error Messages</p> <p>The AWS CLI has been making great improvements to its error messages over time so it is important to pay attention to its output as it can reveal profiles that have been misconfigured with the wrong roles or missing entries.</p>"},{"location":"guide/troubleshooting/credentials/#regenerating-the-aws-config-or-credentials-files","title":"Regenerating the AWS config or credentials files","text":"<p>If you think your AWS config file has misconfigured or missing profile entries (which could happen due to manual editing of that file, or when AWS accounts have been added or remove) you can try regenerating it via Leverage CLI. But before you do that make sure you know which authentication method you are using: SSO or IAM.</p> <p>When using IAM, regenerating your AWS config file can be achieved through the <code>leverage credentials</code> command. Check the command documentation here.</p> <p>When using SSO, the command you need to run is <code>leverage aws configure sso</code>. Refer to that command's documentation for more details.</p>"},{"location":"guide/troubleshooting/credentials/#logging-out-of-your-sso-session","title":"Logging out of your SSO session","text":"<p>Seldom times, when using SSO, we have received reports of strange behaviors while trying to run Terraform commands via the Leverage CLI. For instance, users would try to run a <code>leverage tf init</code> command but would get an error saying that their session is expire; so they would try to log in via <code>leverage aws sso login</code> as expected, which would proceed normally so they would try the init command again just to get the same error as before. In these cases, which we are still investigating as they are very hard to reproduce, what has worked for most users is to log out from the SSO session via <code>leverage aws sso logout</code>, even log out from your SSO session through the AWS console running your browser, then try logging back in via <code>leverage aws sso login</code>, and then try the init command again.</p>"},{"location":"guide/troubleshooting/general/","title":"Troubleshooting general issues","text":""},{"location":"guide/troubleshooting/general/#gathering-more-information","title":"Gathering more information","text":"<p>Trying to get as much information about the issue as possible is key when troubleshooting.</p> <p>If the issue happens while you are working on a layer of the reference architecture and you are using Terraform, you can use the <code>--verbose</code> flag to try to get more information about the underlying issue. For instance, if the error shows up while running a Terraform plan command, you can enable a more verbose output like follows: <pre><code>leverage --verbose tf plan\n</code></pre></p> <p>The <code>--verbose</code> flag can also be used when you are working with the Ansible Reference Architecture: <pre><code>leverage --verbose run init\n</code></pre></p>"},{"location":"guide/troubleshooting/general/#understanding-how-leverage-gets-the-aws-credentials-for-terraform-and-other-tools","title":"Understanding how Leverage gets the AWS credentials for Terraform and other tools","text":"<p>Firstly, you need to know that Terraform doesn't support AWS authentication methods that require user interaction. For instance, logging in via SSO or assuming roles that require MFA. That is why Leverage made the following two design decisions in that regard:</p> <ol> <li>Configure Terraform to use AWS profiles via Terraform AWS provider and local AWS configuration files.</li> <li>Leverage handles the user interactivity during the authentication phase in order to get the credentials that Terraform needs through AWS profiles.</li> </ol> <p>So, Leverage runs simple bash scripts to deal with 2. and then passes the execution flow to Terraform which by then should have the AWS profiles ready-to-use and in the expected path.</p>"},{"location":"guide/troubleshooting/general/#where-are-those-aws-profiles-stored-again","title":"Where are those AWS profiles stored again?","text":"<p>They are stored in 2 files: <code>config</code> and <code>credentials</code>. By default, the AWS CLI will create those files under this path: <code>~/.aws/</code> but Leverage uses a slightly different convention, so they should actually be located in this path: <code>~/.aws/[project_name_here]/</code>.</p> <p>So, for instance, if your project name is <code>acme</code>, then said files should be found under: <code>~/.aws/acme/config</code> and <code>~/.aws/acme/credentials</code>.</p>"},{"location":"guide/troubleshooting/general/#ssh-reiterative-confirmation","title":"SSH reiterative confirmation","text":"<p>If you get a reiterative dialog for confirmation while running a <code>leverage terraform init</code> : <pre><code>Warning: the ECDSA host key for 'YYY' differs from the key for the IP address 'ZZZ.ZZZ.ZZZ.ZZZ'\nOffending key for IP in /root/.ssh/known_hosts:xyz\nMatching host key in /root/.ssh/known_hosts:xyw\nAre you sure you want to continue connecting (yes/no)?\n</code></pre> You may have more than 1 key associated to the <code>YYY</code> host. Remove the old or incorrect one, and the dialog should stop.</p>"},{"location":"guide/troubleshooting/general/#leverage-cli-cant-find-the-docker-daemon","title":"Leverage CLI can't find the Docker daemon","text":"<p>The Leverage CLI talks to the Docker API which usually runs as a daemon on your machine. Here's an example of the error: <pre><code>$ leverage tf shell\n[17:06:13.754] ERROR    Docker daemon doesn't seem to be responding. Please check it is up and running correctly before re-running the command.\n</code></pre></p>"},{"location":"guide/troubleshooting/general/#macos-after-docker-desktop-upgrade","title":"MacOS after Docker Desktop upgrade","text":"<p>We've seen this happen after a Docker Desktop upgrade. Defaults are changed and the Docker daemon no longer uses Unix sockets but TCP, or perhaps it does use Unix sockets but under a different path or user.</p> <p>What has worked for us in order to fix the issue is to make sure the following setting is enabled: </p> <p>Note: that setting can be accessed by clicking on the Docker Desktop icon tray, and then clicking on \"Settings...\". Then click on the \"Advanced\" tab to find the checkbox.</p>"},{"location":"guide/troubleshooting/general/#linux-and-docker-in-rootless-mode","title":"Linux and Docker in Rootless mode","text":"<p>First make sure the user is added to the docker group: </p> <pre><code>$ sudo usermod -aG docker $USER\n$ newgrp docker\n</code></pre> <p>If that does not solve it, then the same problem might come from missing env variable <code>DOCKER_HOST</code>. <code>leverage</code> looks for Docker socket at <code>unix:///var/run/docker.sock</code> unless <code>DOCKER_HOST</code> is provided in environment. If you installed Docker in Rootless mode, you need to remember to add <code>DOCKER_HOST</code> in you rc files: <pre><code>export DOCKER_HOST=unix:///run/user/1000/docker.sock\n</code></pre> or prefix the leverage tool with the env var: <pre><code>$ DOCKER_HOST=unix:///run/user/1000/docker.sock leverage tf shell\n</code></pre></p>"},{"location":"guide/troubleshooting/general/#leverage-cli-fails-to-mount-the-ssh-directory","title":"Leverage CLI fails to mount the SSH directory","text":"<p>The Leverage CLI mounts the <code>~/.ssh</code> directory in order to make the pulling of private Terraform modules work. The error should look similar to the following: <pre><code>[18:26:44.416] ERROR    Error creating container:\n                        APIError: 400 Client Error for http+docker://localhost/v1.43/containers/create: Bad Request (\"invalid mount config for type \"bind\": stat /host_mnt/private/tmp/com.apple.launchd.CWrsoki5yP/Listeners: operation not supported\")\n</code></pre></p> <p>The problem happes because of the file system virtualization that is used by default and can be fixed by choosing the \"osxfs (Legacy)\" option as shown below: </p> <p>Note: that setting can be accessed by clicking on the Docker Desktop icon tray, and then clicking on \"Settings...\". The setting should be in the \"General\" tab.</p>"},{"location":"guide/troubleshooting/general/#leverage-cli-fails-because-of-missing-gitconfig","title":"Leverage CLI fails because of missing .gitconfig","text":"<p>The Leverage CLI might fail when setting up for the first time if there is no <code>~/.gitconfig</code> in your home directory or if it is misconfigured. You will see something similar to: </p> <pre><code>[17:13:43.514] ERROR    Error creating container:\n                        APIError: 400 Client Error for http+docker://localhost/v1.43/containers/create: ... (\"could not find .gitconfig\")\n</code></pre> <p>In order to fix this, just configure git globally: </p> <pre><code>$ git config --global user.name \"Name Lastname\"\n$ git config --global user.email \"name.lastname@email.com\"\n</code></pre>"},{"location":"join-ossverse/","title":"Work with us","text":""},{"location":"join-ossverse/#customers-collaboration-methodology","title":"Customers collaboration methodology","text":"<p>What are all the steps of an engagement</p> <ul> <li> 1<sup>st</sup> Stage: Leverage Customer Tech Intro Interview<ol> <li>Complete our binbash Leverage project evaluation form     so we can get to know your project, find out if you're a good fit and get in contact with you. </li> <li>Schedule a tech intro interview meeting to understand which are your exact challenges and do a Leverage    Reference Architecture feasibility assessment.</li> </ol> </li> <li> 2<sup>nd</sup> Stage: Leverage Reference Architecture Review<ol> <li>If we can contribute, we'll execute a Mutual NDA (ours or yours), then walk your through to complete our binbash Leverage due diligence for Reference Architecture form.</li> <li>Once we completely understand your requirements we'll prepare a comprehensive proposal including the complete    \"Leverage Implementation Action Plan Roadmap\" (also known as Statement     of Work - SOW) detailing every task for the entire project. </li> <li>After you review it and we agree on the general scope, a Services Agreement (SA) is signed.</li> <li>The project kick-off day is scheduled. </li> </ol> </li> <li> 3<sup>rd</sup> Stage: Leverage Ref Architecture Implementation <ol> <li>The Roadmap (SOW) is executed, we'll send an invoice for the deposit and first Sprint starts.</li> </ol> </li> <li> 4rth Stage: binbash Leverage Support<ol> <li>During and after finishing the complete Roadmap we'll provide commercial support, maintenance    and upgrades for our work over the long term.</li> </ol> </li> </ul>"},{"location":"join-ossverse/#work-methodology-intro-video","title":"Work methodology intro video","text":""},{"location":"join-ossverse/#customer-support-workflow","title":"Customer Support workflow","text":""},{"location":"join-ossverse/#read-more","title":"Read More","text":"<p>Related articles</p> <ul> <li> FAQs | Agreement and statement of work</li> </ul>"},{"location":"join-ossverse/contact/","title":"Contact Us","text":"<p>Contact points</p> <ul> <li> \ud83d\udce7 Email | info@binbash.co</li> <li> \ud83c\udf0e Web Site | https://www.binbash.co</li> <li> \ud83c\udfe2 LinkedIn | https://www.linkedin.com/company/binbash</li> <li> \ud83d\udcde Phone | +1 786 2244551</li> <li> \ud83d\udcf1 ** WhatsApp / Telegram |** +54 9351 5510132 || +54 93543 516289</li> <li> \ud83d\udcac ** Slack |** Join Leverage channel </li> </ul> <p>Contact Us </p>"},{"location":"join-ossverse/contribute/","title":"Contribute and Developing binbash Leverage","text":"<p>This document explains how to get started with developing for Leverage Reference Architecture. It includes how to build, test, and release new versions.</p>"},{"location":"join-ossverse/contribute/#quick-start","title":"Quick Start","text":""},{"location":"join-ossverse/contribute/#getting-the-code","title":"Getting the code","text":"<p>The code must be checked out from this same github.com repo inside the binbash Leverage Github Organization.</p> <pre><code>git clone git@github.com:binbashar/le-tf-infra-aws.git\ncd le-tf-infra-aws\ncd ..\n\ngit clone git@github.com:binbashar/le-ansible-infra.git\ncd le-ansible-infra\ncd ..\n</code></pre>"},{"location":"join-ossverse/contribute/#initial-developer-environment-build","title":"Initial developer environment build","text":"<p>TODO</p>"},{"location":"join-ossverse/contribute/#dependencies","title":"Dependencies","text":"<p>This guide requires you to install X v0.1 or newer.</p>"},{"location":"join-ossverse/contribute/#deploying","title":"Deploying","text":"<p>To deploy the Leverage Reference Architecture onto AWS. Please check the deployment guide</p>"},{"location":"join-ossverse/contribute/#testing","title":"Testing","text":"<p>To run tests, just run...</p>"},{"location":"join-ossverse/contribute/#releasing","title":"Releasing","text":""},{"location":"join-ossverse/contribute/#circleci-pr-auto-release-job","title":"CircleCi PR auto-release job","text":"<ul> <li>https://circleci.com/gh/binbashar/bb-devops-tf-infra-aws</li> <li>NOTE: Will only run after merged PR.</li> </ul>"},{"location":"join-ossverse/faqs/","title":"Frequently Asked Questions (FAQs)","text":""},{"location":"join-ossverse/faqs/#target-audience","title":"Target audience","text":"<p>Who is Leverage's target audience?</p> <ul> <li> <p> Leverage is mainly oriented to  Latam, North America and  European startup's CTOs, VPEs, Engineering Managers and/or team leads  (Software Architects / DevOps Engineers / Cloud Solutions Architects)  looking to rapidly set and host their modern web and mobile applications and systems in  Amazon Web Services (\u2705 typically in just a few weeks!). </p> </li> <li> <p> Oriented to Development leads or teams looking to solve their current AWS infrastructure and software delivery  business needs in a securely and reliably manner, under the most modern best practices.</p> </li> <li> <p> Your Entire AWS Cloud solutions based on DevOps practices will be achieved:</p> <ul> <li> Containerization</li> <li> Infrastructure as Code</li> <li> Container Orchestration (K8s) &amp; Application Services</li> <li> CI / CD</li> <li> Security, Compliance &amp; Reliability</li> <li> Cost Optimization &amp; Performance Efficiency</li> <li> Observability &amp; Monitoring</li> </ul> </li> <li> <p> Moreover, if you are looking to have the complete control of the source code, and of course be able to run it without us, such as building new Development environments and supporting your Production Cloud environments,  you're a great fit for the Leverage AWS Cloud Solutions Reference Architecture model.</p> </li> </ul> <p>And remember you could implement yourself or we could implement it for you! \ud83d\udcaa</p>"},{"location":"join-ossverse/faqs/#agreement-and-statement-of-work","title":"Agreement and statement of work","text":""},{"location":"join-ossverse/faqs/#project-kick-off","title":"Project Kick-Off","text":"<p> Project Kick-Off</p> <p>Once the agreement contract and NDA are signed we estimate 15 days to have the team ready to start the project following the proposed Roadmap (\u201cStatement of work\u201d) that describes at length exactly what you'll receive.</p>"},{"location":"join-ossverse/faqs/#assignments-and-delivery","title":"Assignments and Delivery","text":"<p> Assignments and Delivery</p> <p>After gathering all the customer project requirements and specifications we'll adjust the Reference Architecture based on your needs. As a result we'll develop and present the Leverage Reference Architecture for AWS implementation Roadmap. </p> <p>A typical Roadmap (\u201cStatement of Work\u201d) includes a set number of Iterations (sprints).  We try to keep a narrow scope for each Iteration so that we can tightly control how hours get spent to avoid overruns. We typically avoid adding tasks to a running Iteration so that the scope does not grow.  That's also why we have an allocation for to specific long lived tasks:</p> <ul> <li>General-Task-1: DevOps and Solutions Architecture challenge, definitions, tasks (PM), reviews, issues and audit.</li> <li>General-Task-2: WEEKLY FOLLOW-UP Meeting, </li> </ul> <p>Which is work that falls outside of the current Iteration specific tasks. This is for special requests, meetings, pair programming sessions, extra documentation, etc.</p> <p>binbash will participate and review the planned tasks along the customer:</p> <ul> <li> planned roadmap features</li> <li> bug fixes</li> <li> Implementation support</li> </ul> <p>Using the relevant ticketing system (Jira) to prioritize and plan the corresponding work plan.</p>"},{"location":"join-ossverse/faqs/#reports-and-invoicing","title":"Reports and Invoicing","text":"<p> Reports and Invoicing</p> <p>Weekly task reports and tasks management agile metrics. We use Toggl to track all our time by client, project, sprint, and developer. We then import these hours into Quickbooks for invoicing.</p>"},{"location":"join-ossverse/faqs/#rates-and-billing","title":"Rates and Billing","text":"<p> Rates and pricing plans</p> <ul> <li> <p> Pre-paid package subscriptions: A number of prepaid hours is agreed according to the needs  of the project. It could be a \"Basic Plan\" of 40 hours per month. Or a \"Premium Plan\" of 80 hours per month (if more hours are needed it could be reviewed). When buying in  bulk there is a discount on the value of the hour. When you pay for the package you start discounting the hours from the total as they are used, and if there are unused hours left, consider that maximum 20%  could be transferred for the next month.</p> </li> <li> <p> On-demand Business Subscription: There are a certain number of hours tracked each month, as planned tasks are demanded. The total spent hours will be reported  each month. There is a monthly minimum of 40 hours per month. Support tasks maximum estimated effort should be between 80 and 120 hs / month.</p> </li> </ul> <p> Billing</p> <p>The Customer will be billed every month. Invoices are due within 15 days of issue. We accept payments via US Bank ACH, Bill.com, and Payoneer. Rates include all applicable taxes and duties as required by law.</p>"},{"location":"join-ossverse/support/","title":"Support","text":""},{"location":"join-ossverse/support/#leverage-reference-architecture","title":"Leverage Reference Architecture","text":"<p>Please create a Github Issue to get immediate support from the binbash Leverage Team</p>"},{"location":"join-ossverse/support/#our-engineering-support-team","title":"Our Engineering &amp; Support Team","text":""},{"location":"join-ossverse/support/#aws-well-architected-review","title":"AWS Well Architected Review","text":"<p>Feel free to contact us for an  AWS Well Architected Framework Review </p> <p></p> <p> Well Architected Framework Review Reference Study Case</p> <ul> <li> Operational Excellence</li> <li> Security</li> <li> Cost Optimization</li> <li> Reliability</li> <li> Performance Efficiency</li> </ul> <p>WAF Exta Material</p> <ul> <li> DevSecOps Security Audit - v0.1</li> <li> WAF Cost Optimization Checklist - v0.1</li> </ul>"},{"location":"join-ossverse/support/#read-more","title":"Read More","text":"<ul> <li>How AWS Well-Architected Reviews Can Drive a Customer-First Culture</li> </ul>"},{"location":"join-ossverse/testimonials/","title":"Testimonials (by industry)","text":""},{"location":"join-ossverse/testimonials/#helthcare-clinics-real-state-travel","title":"Helthcare (Clinics) &amp; Real State &amp; Travel","text":"<p>Yury Yakubchyk | Founder, Investor, Board Member &amp; Advisor @ Multiple US Industries</p> <p></p> <ul> <li>\ud83c\udf0e Company website: lifehousehotels.com</li> <li> <p>\ud83c\udf0e Company website: joinsprouttherapy.com</p> </li> <li> <p> \"We utilized BinBash to help get our DevOps infrastructure launched and manage all aspects of our AWS-based setup. Their security and compliance focus turned out to be a great fit for our HIPAA regulation needs.  We\u2019ve been very pleased with their responsiveness and thoroughness with regards to our technology needs and  would be happy to work with them again in the future.\"</p> </li> </ul>"},{"location":"join-ossverse/testimonials/#edtech-education","title":"EdTech (Education)","text":"<p>Alejandro Parise | Founder &amp; CEO @ Latam &amp; North America EdTech Industry</p> <p></p> <p>\ud83c\udf0e Company website: e-valuados.com</p> <ul> <li> \"binbash provided us with cloud architecture consulting at a critical time for our company. Prior to our production go-live they reviewed in-depth our application architecture. Resulting in several optimization points, with focus on response time, security, costs, monitoring, DB data sets, backups &amp; restore. They truly exceeded our expectations and provided support when e-valuados greatly needed it.\"</li> </ul>"},{"location":"join-ossverse/testimonials/#banking-fintech-and-insurtech","title":"Banking, Fintech and Insurtech","text":"<p>Martin Vago | IT &amp; CloudOps Manager @ Latam Fintech Industry</p> <p></p> <p>\ud83c\udf0e Company website: tunubi.com</p> <ul> <li> \"binbash has a focused and highly productive professional team. They have exceptional tech skills and effectively transmit and implement their solutions, such as Leverage. Thanks to their collaboration we managed to have a superlative product hosted in AWS. It is undoubtedly a company with which I would like to work in any challenge that lies ahead\"</li> </ul> <p>Felipe Lerena | Software Architect &amp; Dev Lead @ Latam Fintech Industry</p> <p></p> <p>\ud83c\udf0e Company website: tunubi.com</p> <ul> <li> \"binbash helped us build a resilient, future-proof infrastructure in record time. They will not only do things for you, they will transfer all the knowledge and make you  part of the decision. They are always thinking about re-usability, security and scale.  The binbash team is not only technically proficient but they are really nice human beings.\"</li> </ul> <p>Juan Manuel Rodrigo | CTO @ Latam Fintech / Banking / Insurtech Industries</p> <p></p> <p>\ud83c\udf0e Company website: flexibility.com.ar</p> <ul> <li> \"We found the right AWS and DevOps technology partner at binbash, who quickly interpreted our core business, and while working together we identified quick gains that helped us to significantly differentiate our cloud native solution. Moreover, their product, Leverage resulted in an AWS automation framework that accelerated our business roadmap,  highlighting the technical talent of the binbash team for its rapid and solid implementation.\"</li> </ul> <p>Alejandro Creta | Infrastructure Architecture Lead @ Latam Fintech / Banking / Insurtech Industries</p> <p></p> <p>\ud83c\udf0e Company website: flexibility.com.ar</p> <ul> <li> \"Our experience with binbash Leverage has been overwhelmingly positive. It allowed us to adopt AWS Well-Architected Framework and Infrastructure as Code in an accelerated and efficient way without losing  compatibility with the tool's stardards we're using such as Terraform, Ansible and Helm.  The project planning and the work methodology helped us to strengthen our DevOps culture in the areas involved  such as loosely couple cloud architecture, development &amp; CI/CD, monitoring, shift left on security and audit,  adding important cultural values such as collaboration, continuous improvement and knowledge transfer.\"</li> </ul>"},{"location":"join-ossverse/testimonials/#media-entertainment-streaming","title":"Media &amp; Entertainment (Streaming)","text":"<p>Max Ivanov | Software Architect @ US Media Entertainment Industry</p> <p></p> <ul> <li> \"binbash has a focused and highly productive professional team. They have exceptional tech skills and effectively transmit and implement their solutions, such as Leverage. Thanks to their collaboration we managed to have a superlative product hosted in AWS. It is undoubtedly a company with which I would like to work in any challenge that lies ahead\"</li> </ul>"},{"location":"join-ossverse/testimonials/#cyber-security-risk-management","title":"Cyber Security &amp; Risk Management","text":"<p>Franco Gauchat | DevSecOps Engineer @ Cyber Security Industry</p> <p></p> <p>\ud83c\udf0e Company website: btrconsulting.com </p> <ul> <li> \"binbash team is highly experienced and skilled in DevOps practices and AWS cloud solutions. I have worked very closely with them on a large scale Fintech project and have demonstrated a deep understanding of our deployed AWS infrastructure. They collaborate with us to design and implement the best possible course of action for each of our applications based on short and long term business and security goals.  Including cloud architecture, security, audit, monitoring, centralized logs, deployments, infra as code,  scalability and performance.  Hope our paths cross again very soon.\"</li> </ul> <p>Horacio G. de Oro | Head of DevOps @ Risk Management US Industry</p> <p></p> <p>\ud83c\udf0e Company website: thirdpartytrust.com </p> <ul> <li> \"binbash redesigned and helped us to develop our entire AWS Cloud Solutions Architecture under a IaC (InfraAsCode) best practice approach, and always taking care of the environment security. Including our new AWS Organizations Multi-Account and Kubernetes deployment infrastructure. The binbash team managed the entire engagement effectively and within budget. The team members are knowledgeable, proactive, work collaboratively, offer solid and creative solutions, communicate well, and deliver timely and high quality work products, such as Leverage. We highly recommend binbash for your AWS cloud infrastructure implementation.\"</li> </ul>"},{"location":"join-ossverse/testimonials/#sports-and-events","title":"Sports and Events","text":"<p>Leandro Basso | Co-Founder &amp; BizDev Manager @ Latam Sports and Events Industry</p> <p></p> <p>\ud83c\udf0e Company website: hayturno.com </p> <ul> <li> \"When our company The Ideas Factory was in search of a new DevOps team, we looked for a partnership that would not only help direct us into the modern world, but also one that understood our business. binbash DevOps Cloud Services performed over and above our expectations, and the initial response from visitors of our remodeled WebApp has been overwhelmingly positive.\"</li> </ul>"},{"location":"join-ossverse/testimonials/#digital-advertising-marketing","title":"Digital Advertising / Marketing","text":"<p>Alina Fermo | Project Manager @ US Digital Marketing Industry</p> <p></p> <p>\ud83c\udf0e Company website: grey.com </p> <ul> <li> \"I\u00b4ve got the pleasure to work with binbash leaders in the recent past. I was managing client side DevOps project for a US Digital Marketing customer and I have only good things to say about them. Good professionals and  also kind persons. They are those people you hope to have in all your projects. They are always there to give an efective response to the client, to suggest good practices, improvements with excellent communication skills.  When I needed them, they were always there to solve our issues and attend our requests.  Moreover, one of the binbash Tech architected several of our project applications and also work along with their team in achieving continuous integration implementation and kick-off.Their sense of urgency and his ability to discover  potential risks are great, as well as finding the best way to solve problems when facing them. There is nothing bad I can say about these guys. I only wish someday to have the pleasure to work with them again.\"</li> </ul>"}]}